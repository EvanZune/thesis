% Chapter 5

\chapter{WiNoCoD Bandwidth Allocation Algorithms} % Main chapter title

\label{Chapter5} % For referencing the chapter elsewhere, use \ref{Chapter1} 

\lhead{Chapter 5. \emph{WiNoCoD Bandwidth Allocation}} % This is for the header on each page - perhaps a shortened title


In Chapter 4, the new problem of service allocation to multiple parallel queues, in multiple symbols is conceptualized, which is a fundamental projection of WiNoCoD subcarrier arbitration issue. Main metrics and goals of interest such as minimizing average latency, limiting delay-rate function or fairness have been discussed in detail also. Several approaches to this problem from literature are proposed in Chapter 4, along with their optimality under certain assumptions. Chapter 4 induces a broad sense of multi-user scheduling in general. Furthermore, preliminary concepts of subcarrier allocation for WiNoCoD due to unorthodox nature of on-chip architecture were presented in detail. Chapter 5, covers the proposed effective bandwidth allocation for the new problem of WiNoCoD's OFDMA RF interconnect. Under various configurations and input traffic models, pros-cons, feasibility and performance of proposed algorithms are evaluated extensively and classified as a tree diagram at the end of the chapter.     


\section{Serial QSI Allocation}

\subsection{Regular Serial QSI Allocation}

First algorithm we propose is a relatively straight-forward one. After QSIs are broadcasted and acquired by each tileset, they allocate RBs in a frame (RB matrix) serially, looping through the QSI values of tilesets, i.e. serving requests of tilesets one-by-one. The algorithm terminates when there is no RBs left to allocate or if all requests of tilesets are served. In case, total QSI of all tilesets is fewer than the total number of RBs in the frame, the remaining RBs are shared using default allocation matrix as in Section 4.3.3.5. 

One can claim that, RB allocation can also be done one-by-one, looping each time through tilesets for each RB to allocate or with a completely different approach, however limiting the number of iterations is highly essential. Previously presented in Section 4.2.1, well known LQF requires high number of iterations like this. Considering our temporal budget of few hundreds of processor cycles for bandwidth arbitration computation, iterating through 32 tilesets only once is feasible.  

Starting allocation from the same tileset in every allocation epoch will cause an unfairness, as first nodes will have priority for acquiring RBs. In these cases, if RBs are taken by these priority nodes, the rest will likely to starve. In order to avoid this, we propose a simple rotating priority scheme, that cyclically starts from the next tileset, every allocation epoch. 

As serial allocation is a simple consecutive assignment of RBs to tilesets, no mathematical or computational demand exists. Hence, employing this algorithm in a decentralized allocation architecture is not too costly. However for the sake of coherency, we also perform our experimentation on serial allocation algorithm with centralized approach. 

\subsubsection{Decentralized Approach}

Tilesets broadcast their QSIs on reserved subcarriers each T symbols (frame) as in Fig. 4.5. Then starting from the tileset with the instantaneous priority, the RBs equal to QSI demand of each tileset is allocated iteratively, based on the direction of allocation. Allocation terminates when there are no RBs left or the iteration is finished (i.e. all demands of tilesets are served). As allocation is performed on the default allocation matrix, if there are remaining RBs after iteration, they are arbitrated as explained in Section 4.3.3.5. Note that, in order to avoid inconsistency for bandwidth allocation and reulting congestion, each tileset shall perform the same algorithm without any error.
  
\textit{Average Latency}


First, we evaluate the average latency performance of decentralized serial allocation algorithm with increasing injection rate for 4 different frame lengths ($T=4, 8, 16$ and $32$) under 3 stochastic traffic models explained in Section 4.3.4.2. As mentioned previously, different frame lengths may be imposed by the circuital constraints or be an intended choice. Longer frame lengths decrease the signaling overhead eventually, increasing the useful communication bandwidth. Framed and pipelined allocation is the result of the short symbol durations, where we have to spare certain amount of time to microprocessors and components to reconfigure bandwidth occupation. Table 5.1 lists the total number of RBs for different lengths of frames and associated QSI signaling overhead percentage. As there may be different choices for the processing speeds of bandwidth reconfiguration units, we evaluate the proposed allocation algorithms for various frame lengths.   


\begin{table}[]
\centering
\caption{Total number of RBs for different lengths of frames and associated QSI signaling overhead percentage.}
\label{Total number of RBs for different lengths of frames and associated QSI signaling overhead percentage.}
\begin{tabular}{|c|c|c|}
T (symbols)			& Number of RBs    & Overhead (\%)     \\ \hline	
4                    & 128    & 3.21     \\ \hline
8        &256    & 1.56  \\ \hline
16      & 512   & 0.78 \\ \hline
32 & 1024    & 0.39  \\ \hline
\end{tabular}
\end{table}


Fig. 5.1 shows the average latency curves under Uniform Poisson Traffic model, where the spatial or temporal variance is least. Before starting to evaluate the results, we would like to highlight a previously mentioned important aspect, which is known as the \textit{network capacity} in queuing and network theory. When the average injection rate (input) surpasses the average service rate (i.e. utilization $\rho>1$), the queue backlogs start to grow continuously, resulting in practically infinite average latency. Also, as average latency of a system grows quadrically with the utilization, even $\rho$ values approaching 1 may cause very high latencies. In our WiNoCoD interconnect, as we have 1024 subcarriers encoded by QPSK, it can serve 2048 bits or 32 flits per symbol. As 25\% of packets are 9 flits and 75\% of packets are 1 flit long, the average service demand of a packet is 3 flits. Therefore, system capacity in our case is $32/3 = 10.66$ packets/symbol. In Fig. 5.1, we observe that near optimal OPF algorithm for each T values, is able to reach a point near to this theoretical capacity. However, for lower injection rates, OPF is performing remarkably worse compared to the allocation algorithm, because when the number of packets present in the queues is low, infrequent repartition (not every symbol, but every few symbols) of the bandwidth according to instantaneous latencies of the packets is not a valid approach. Therefore, we can state OPF does not constitute an efficient reference for low injection rates, but for the injection rates closer the system capacity.     



\begin{figure}[htbp]
  \centering
    \includegraphics[width=0.70\textwidth]{./Chapter5_Figures/serial_decentral_plain_UniPoiss_copy.eps}
    \rule{35em}{0.5pt}
  \caption[Decentralized Serial Allocation Average latency under uniform Poisson]{Average latency curves under uniform Poisson traffic with increasing injection rate for decentralized serial allocation algorithm.}
  \label{fig:Electron}
\end{figure}


Most remarkable results for uniform Poisson case with decentralized serial allocation is the relatively worse performance for $T=4$ symbols, for injection rates larger than 5 packets/symbol. One would expect to see the shortest frame length to perform best as a result of more frequent, thus more accurate QSI information. As serial allocation, takes the broadcasted QSIs and allocates RBs serially to tilesets without any sophisticated treatment, when injection rate increases, tilesets' QSI values starts to increase also. Hence, when we have a short frame length, we have practically small number of RBs to allocate. For $T=4$ there are 124 RBs are available when QSI signaling subcarriers are excluded. In this case, when the QSI demands of tilesets are large, only one or few of the tilesets grab all the RBs in a frame. Even though, we have a rotating priority mechanism, this unfairness results in very large waiting times for tilesets to be served. We see from Fig. 5.1, this starvation effect deteriorates as frame length gets longer. In contrary, for small injection rates, shorter frame length, thus more frequent allocation shows better performance as expected. 


Another interesting observation is on the direction of RB allocation. We observe that generally frequency direction allocation incurs a lower average latency compared to time direction. This roots from the default allocation matrix which reserves 1 RB for each tileset, when all QSI demands are served. In first few symbols of a frame, QSI demands of tilesets are served in chunks once at a time by using multiple RBs in a single symbol. When all allocation is terminated, the rest is partitioned uniformly.


As a next step, we evaluate the same curves under non-uniform Poisson traffic and non-uniform DPBPP traffic with H=0.9, in Fig. 5.2 and Fig. 5.3, respectively. 



\begin{figure}[htbp]
  \centering
    \includegraphics[width=0.70\textwidth]{./Chapter5_Figures/serial_decentral_plain_NonuniPoiss_copy.eps}
    \rule{35em}{0.5pt}
  \caption[Decentralized Serial Allocation Average latency under non-uniform Poisson]{Average latency curves under non-uniform Poisson traffic with increasing injection rate for decentralized serial allocation algorithm.}
  \label{fig:Electron}
\end{figure}


\begin{figure}[htbp]
  \centering
    \includegraphics[width=0.70\textwidth]{./Chapter5_Figures/serial_decentral_plain_DPBPP_copy.eps}
    \rule{35em}{0.5pt}
  \caption[Decentralized Serial Allocation Average latency under non-uniform DPBPP]{Average latency curves under non-uniform DPBPP traffic with increasing injection rate for decentralized serial allocation algorithm.}
  \label{fig:Electron}
\end{figure}

As it can be noticed from figures above, the most interesting result is the better performance of $T=32$ than others under non-uniform DPBPP traffic in terms of approaching the system capacity. This is due to same starvation effect with lower frame lengths explained above. However, for smaller injection rates, still, the lower frame lengths show better performance as expected. Only, in uniform and non-uniform Poisson process, we see that $T=8$ symbols of frame length is able to approach to system limit surprisingly, possibly due to being an effective compromise between frequent QSI signaling and low number of RBs to allocate once at a time. 

\pagebreak

\textit{Packet Delay and Queue Length Bound Exceeding Probabilities}

Next, we evaluate the delay and queue length exceeding probability curves (i.e. inverse cumulative probability distribution function) for different frame lengths for decentralized serial allocation algorithm. These curves give a good understanding on maximum delay a packet can experience or the necessary buffer capacity etc. as explained in Section 4.3.4.1. These curves are evaluated only for realistic and stressing non-uniform DPBPP traffic due to absence of space. By looking at Fig. 5.3, we see that for injection rates larger than 8 packets/symbol, all frame lengths fails (i.e. blows up), therefore we have selected an injection rate of 7 packets/symbol for this evaluation, where each frame length provides a reasonable average latency.

Fig. 5.4(a) and Fig. 5.4(b) show the probability graphs for a packet to exceed a certain delay or a transmission queue to exceed a threshold on any symbol, respectively. 



\begin{figure*}[htbp]
  \centering
  \begin{tabular}[c]{cccc}

  \subcaptionbox{}[.5\linewidth][]{%
    \includegraphics[width=0.48\textwidth, height =0.4\textwidth]{./Chapter5_Figures/serial_decentral_plain_DPBPP_delayOverflow_copy.eps} }	
    
  \subcaptionbox{}[.5\linewidth][]{%
    \includegraphics[width=0.48\textwidth, height =0.4\textwidth]{./Chapter5_Figures/serial_decentral_plain_DPBPP_queueOverflow_copy.eps}}
 
   \end{tabular}

  \caption{Packet Delay (a) and Queue Length (b) exceeding probability graphs for decentralized serial allocation algorithm under non-uniform DPBPP traffic (log-linear)}
\end{figure*}


For instance, we observe in Fig. 5.4(a), that probability for a packet experiencing a delay between 30 and 70 symbols, is smallest for the frame length of 16 symbols with time direction allocation. However, for instance, probability of a packet experiencing a delay larger than 20 is minimum for $T=4$ symbols and time direction allocation is around 0.5. Recalling an OFDM symbol is larger than 50 ns, one can claim that decentralized serial allocation does not perform well under an injection rate of 7 packets/symbol. For queue length exceeding graph, best performance for all thresholds is by T=16 symbols in time direction. For instance, under this configuration probability for a transmission queue of a tileset to have more than 50 flits on a symbol is around 0.01.  


\subsubsection{Centralized Approach}
Whereas we have mentioned utilizing serial QSI allocation algorithm in centralized approach is not that much interesting due to no computation, however we perform the same experimentation procedure in previous section. As it was stated in Section 4.3.3.3, we give a certain amount of time for tilesets to receive allocation response from the CIU and reconfigure their transmissions. Throughout this thesis, when we are comparing centralized approach to decentralized approach, we always used a $T_{reconfig} = 2$ symbols. Hence, when comparing a decentralized frame length of 4 symbols (mainly due to computation time), we use a 6 symbols of frame length for the centralized approach. Recall that, in centralized approach we additionally have RBs reserved for transmission of response packets. 

Fig. 5.5, Fig. 5.6 and Fig. 5.7 show the average latency with increasing injection rate under 3 different stochastic models for centralized serial allocation algorithm. One cannot see any substantial difference between the decentralized case, except for the difference between the decentralized allocation with $T=4$ symbols under uniform Poisson traffic. With centralized approach, we have a total frame length of 6 symbols, which eliminates the aforementioned starvation effect.

\begin{figure}[htbp]
  \centering
    \includegraphics[width=0.7\textwidth]{./Chapter5_Figures/serial_central_plain_UniPoiss_copy.eps}
    \rule{35em}{0.5pt}
  \caption[Centralized Serial Allocation Average latency under uniform Poisson]{Average latency curves under uniform Poisson traffic with increasing injection rate for centralized serial allocation algorithm.}
  \label{fig:Electron}
\end{figure}

\begin{figure}[htbp]
  \centering
    \includegraphics[width=0.7\textwidth]{./Chapter5_Figures/serial_central_plain_NonuniPoiss_copy.eps}
    \rule{35em}{0.5pt}
  \caption[Centralized Serial Allocation Average latency under non-uniform Poisson]{Average latency curves under non-uniform Poisson traffic with increasing injection rate for centralized serial allocation algorithm.}
  \label{fig:Electron}
\end{figure}


\begin{figure}[htbp]
  \centering
    \includegraphics[width=0.7\textwidth]{./Chapter5_Figures/serial_decentral_plain_DPBPP_copy.eps}
    \rule{35em}{0.5pt}
  \caption[Centralized Serial Allocation Average latency under non-uniform DPBPP]{Average latency curves under non-uniform DPBPP traffic with increasing injection rate for centralized serial allocation algorithm.}
  \label{fig:Electron}
\end{figure}


Packet delay and queue length exceeding probability graphs are also investigated, as for the decentralized case. Fig. 5.8 shows the similar performance of centralized case to decentralized case. 

\begin{figure*}[htbp]
  \centering
  \begin{tabular}[c]{cccc}

  \subcaptionbox{}[.5\linewidth][]{%
    \includegraphics[width=0.48\textwidth, height =0.4\textwidth]{./Chapter5_Figures/serial_central_plain_DPBPP_delayOverflow_copy.eps} }	
    
  \subcaptionbox{}[.5\linewidth][]{%
    \includegraphics[width=0.48\textwidth, height =0.4\textwidth]{./Chapter5_Figures/serial_central_plain_DPBPP_queueOverflow_copy.eps}}
 
   \end{tabular}

  \caption{Packet Delay (a) and Queue Length (b) exceeding probability graphs for centralized serial allocation algorithm under non-uniform DPBPP traffic (log-linear)}
\end{figure*}

\subsection{Serial QSI with 2-loop Allocation}

Most unsatisfactory result from the regular serial QSI allocation algorithm was its significantly low performance in terms of approaching the network capacity. Most interestingly, frequent bandwidth allocation with very short frame length causes a significant increase in average latency. For instance, for a frame length of 4 symbols, regular QSI allocation causes to system to blow in terms of average latency, for injection rates larger than 6 packets/symbol. We have observed that this contradicting effect is due to low number of RBs to allocate under short frame lengths. By using neutral priority, certain tilesets exhaust RBs, starving tilesets who really need resources.  

We have mentioned that the main motivation behind suggesting regular serial QSI allocation algorithm was its very low computational requirements, where only a single iteration of tilesets is performed. However, based our experiments, we have seen that this algorithm shall be improved through further modifications. In order to solve this fairness problem, and even increase the fairness among tileset transmission queues, we have established a modification of serial QSI allocation algorithm. 

This time allocation of RBs is performed in 2 stages, as the name suggests. Firstly after receiving QSIs of each tileset, they are summed and divided to number of tilesets to obtain the \textquotedblleft average QSI\textquotedblright on current frame. This average QSI value is an integer, and found by upper rounding the result. At the first stage of the algorithm, 32 tilesets are iterated as in the previous simple serial allocation. However on this first loop, only tilesets who have a larger QSI than the current \textquotedblleft average QSI\textquotedblright can grab RBs. After this first iteration, QSI values are updated by substracting the already allocated RBs in this frame. Followingly, at the second stage, the same iteration through tilesets are performed by their updated QSI values, this time as the default serial allocation algorithm. By this way, we make sure that tilesets who really need RBs get its share. This extension to regular serial QSI allocation algorithm can be seen as an attempt to compensate imbalances in queues. It is widely admitted in queuing theory that, optimal scheduling algorithms in terms of latency minimization, are the ones who balances the queues more effectively \cite{kittipiyakul2009delay}.

However, note that this algorithm may introduce another dimension of unfairness. If certain high load tilesets keep being over the average QSI, and exhaust all the RBs in first stage; other active tilesets with low QSI values may not grab resources for very long time. This starvation issue can be solved simply by by-passing first stage periodically every certain frames. However, this issue is not discussed in this thesis.

Note that, this modification does not only require an extra iteration, but also introduces mathematical operations such as 32 32-bit summations, a single division, 32 binary comparisons etc. Hence, it presents a certain degree of computational cost compared to regular QSI allocation.
 
\subsubsection{Decentralized Approach}
In decentralized approach, each tileset first calculates the \textquotedblleft average QSI\textquotedblright by themselves, based on the broadcasted QSI values by all other tilesets. Then through the first iteration RBs are arbitrated in allocation matrix in time or frequency direction. The second iteration continues to allocate RBs from the last RB of the first iteration. This way, allocation or RBs are pipelined and faster.

\textit{Average Latency}

We perform our usual average latency experiments for this method to evaluate whether proposed modification increases the performance. 



\begin{figure}[htbp]
  \centering
    \includegraphics[width=0.7\textwidth]{./Chapter5_Figures/serial_decentral_2loop_UniPoiss_copy.eps}
    \rule{35em}{0.5pt}
  \caption[Decentralized Serial 2-loop allocation average latency under uniform Poisson]{Average latency curves under uniform Poisson traffic with increasing injection rate for decentralized serial 2-loop allocation algorithm.}
  \label{fig:Electron}
\end{figure}


\begin{figure}[htbp]
  \centering
    \includegraphics[width=0.7\textwidth]{./Chapter5_Figures/serial_decentral_2loop_NonuniPoiss_copy.eps}
    \rule{35em}{0.5pt}
  \caption[Decentralized Serial 2-loop allocation average latency under non-uniform Poisson]{Average latency curves under non-uniform Poisson traffic with increasing injection rate for decentralized serial 2-loop allocation algorithm.}
  \label{fig:Electron}
\end{figure}


\begin{figure}[htbp]
  \centering
    \includegraphics[width=0.7\textwidth]{./Chapter5_Figures/serial_decentral_2loop_DPBPP_copy.eps}
    \rule{35em}{0.5pt}
  \caption[Decentralized Serial 2-loop allocation average latency under non-uniform DPBPP]{Average latency curves under non-uniform DPBPP traffic with increasing injection rate for decentralized serial 2-loop allocation algorithm.}
  \label{fig:Electron}
\end{figure}

Comparing Fig. 5.9, Fig. 5.10 and Fig. 5.11 to Fig. 5.1, Fig. 5.2 and Fig. 5.3, respectively; we see a substantial performance increase. Thanks to its added fairness, this algorithm is able to reach near the network capacity. Most remarkable result is for the shortest frame length of $T=4$ symbols. With 2-loop modification, now with a frame length of $T=4$ symbol performs best compared to longer frame lengths as expected. 

We have seen in previous section that, even though exchanging QSI more frequently should give lower average latencies, due to starvation phenomenon explained, it was degrading the performance. Now, by this simple modification with very limited additional complexity, we have shown that this effect can be mitigated. 

By inspecting, Fig. 5.9, Fig. 5.10 and Fig. 5.11, we can claim that proposed algorithm induces reasonable and scalable average latencies, especially for short frame lengths. Considering it has very limited computational requirements, we can state this algorithm can be implemented easily for $T=4$ or $8$ symbols, while we are taking all other delays incurred due to reconfiguration, propagation, serialization, packet treatment etc.

Another point to mention is on the direction of RB allocation. Different than the previous case, we see that now both direction of allocation in frequency or time, achieves nearly the same capacity. For lower injection rates, frequency direction provides lesser average latency. This is due to the fact that by allocating RBs in frequency direction, tilesets with large QSIs are able to be serve all packets in few symbols. Of course, as frame lengths longer, the gap between frequency and time direction allocation widens. 

\textit{Packet Delay and Queue Length Bound Exceeding Probabilities}


Next, in order to compare the improvement of this 2-loop algorithm we evaluate the packet delay and queue length exceeding probability graphs under realistic non-uniform DPBPP traffic. However, instead of 7 packets/symbol injection rate we choose to inspect the performance under higher traffic load. 7 packets/symbol of injection rate was a threshold, where all different frame lengths were under network capacity. Thanks to fairness with 2-loop algorithm, this threshold is further expanded. Hence, we choose an injection rate of 10 packets/symbol for the evaluation of maximum delay and buffer capacity. 

 \begin{figure*}[htbp]
  \centering
  \begin{tabular}[c]{cccc}

  \subcaptionbox{}[.5\linewidth][]{%
    \includegraphics[width=0.48\textwidth, height =0.4\textwidth]{./Chapter5_Figures/serial_decentral_2loop_DPBPP_delayOverflow_copy.eps} }	
    
  \subcaptionbox{}[.5\linewidth][]{%
    \includegraphics[width=0.48\textwidth, height =0.4\textwidth]{./Chapter5_Figures/serial_decentral_2loop_DPBPP_queueOverflow_copy.eps}}
 
   \end{tabular}

  \caption{Packet Delay (a) and Queue Length (b) exceeding probability graphs for decentralized serial 2-loop allocation algorithm under non-uniform DPBPP traffic (log-linear) under 10 packets/symbol injection rate}
\end{figure*}

Even under an injection rate of 10 packets/symbol with severe temporal and spatial burstiness, by evaluating Fig. 5.12, we see that serial allocation with 2-loop modification provides reasonable delays for packets and buffer capacities, despite its low computational complexity. However, considering an OFDM symbol is longer than 50 ns and strict requirements of on-chip packets, one can argue this performance gain is not sufficient, especially when the traffic load is high. For example, from Fig. 5.20(a), we see that probability for a packet in any queue in the system to experience a delay larger than 50 symbols is approximately 0.1, even under a frame length of 4 symbols. 

\subsubsection{Centralized Approach}
In centralized version of the 2-loop serial allocation, CIU is responsible of acquiring QSIs, calculate the average QSI, than perform the allocation in 2 iterations. However, different than the decentralized approach, CIU first calculates the total number of RBs allocated to each tileset and broadcasts them in response. Then tilesets reconfigure their transmission matrix, simply by occupying RBs consecutively based on the direction of allocation. Even though, the computational burden is minimal for this type of an algorithm, we choose to implement the centralized version of it.

\textit{Average Latency}


First, average latency performance with increasing injection rate under 3 different stochastic models are evaluated.
  
\begin{figure}[htbp]
  \centering
    \includegraphics[width=0.7\textwidth]{./Chapter5_Figures/serial_decentral_2loop_UniPoiss_copy.eps}
    \rule{35em}{0.5pt}
  \caption[Centralized Serial 2-loop allocation average latency under uniform Poisson]{Average latency curves under uniform Poisson traffic with increasing injection rate for centralized serial 2-loop allocation algorithm.}
  \label{fig:Electron}
\end{figure}


\begin{figure}[htbp]
  \centering
    \includegraphics[width=0.7\textwidth]{./Chapter5_Figures/serial_decentral_2loop_NonuniPoiss_copy.eps}
    \rule{35em}{0.5pt}
  \caption[Centralized Serial 2-loop allocation average latency under non-uniform Poisson]{Average latency curves under non-uniform Poisson traffic with increasing injection rate for centralized serial 2-loop allocation algorithm.}
  \label{fig:Electron}
\end{figure}


\begin{figure}[htbp]
  \centering
    \includegraphics[width=0.7\textwidth]{./Chapter5_Figures/serial_decentral_2loop_DPBPP_copy.eps}
    \rule{35em}{0.5pt}
  \caption[Centralized Serial 2-loop allocation average latency under non-uniform DPBPP]{Average latency curves under non-uniform DPBPP traffic with increasing injection rate for centralized serial 2-loop allocation algorithm.}
  \label{fig:Electron}
\end{figure}

From Fig. 5.13, Fig. 5.14 and Fig. 5.15, we see that despite having an extra signaling overhead for response and 2 symbols of additional latency for reconfiguration, average latency performance is degraded slightly. 

\textit{Packet Delay and Queue Length Bound Exceeding Probabilities}


To check the delay fairness and maximum buffer occupancy, next we inspect the packet delay and queue length exceeding probability graphs under non-uniform DPBPP traffic with 10 packets/symbol injection rate. 

As it can be seen in Fig. 5.16, centralized version of the 2-loop serial allocation does not provide drastically changed delay and queue length exceeding probability performance, due to 2 symbol extra latency or additional overhead and block allocation of RBs. 


\begin{figure*}[htbp]
  \centering
  \begin{tabular}[c]{cccc}

  \subcaptionbox{}[.5\linewidth][]{%
    \includegraphics[width=0.48\textwidth, height =0.4\textwidth]{./Chapter5_Figures/serial_central_2loop_DPBPP_delayOverflow_copy.eps}}	
    
  \subcaptionbox{}[.5\linewidth][]{%
    \includegraphics[width=0.48\textwidth, height =0.4\textwidth]{./Chapter5_Figures/serial_central_2loop_DPBPP_queueOverflow_copy.eps}}
 
   \end{tabular}

  \caption{Packet Delay (a) and Queue Length (b) exceeding probability graphs for centralized serial 2-loop allocation algorithm under non-uniform DPBPP traffic (log-linear) under 10 packets/symbol injection rate}
\end{figure*}

\subsection{Serial QSI Allocation with DQSI and EQSI}

We have previously introduced the notion of Definitive Queue State Information (DQSI) and Expected Queue State Information (EQSI) in Section 4.3.3.7, to cope the outdated QSI due to pipelined allocation. We have seen the possible augmentation of capacity by employing a simple 2-loop modification. Now, we will investigate serial allocation algorithm under DQSI and EQSI modification. As $\alpha$ can take a vast amount of different values, due to absence of space, we only investigate the performance under $\alpha = 0.95$, which is generally provides the best performance in most of the scenarios.

\subsubsection{Decentralized Approach}
As mentioned in Section 4.3.3.7, in decentralized approach, each tileset computes its own DQSI or EQSI value by using currently allocated number of RBs and/or instantaneous moving average. Then, this value is broadcasted on the first symbol of the next frame. Then, as in the plain serial allocation in Section 5.1.(a), the RB allocation is performed in frequency or time direction, using these values. 

\textit{Average Latency}


Firstly, we investigate the average latency with increasing injection rate with DQSI and EQSI based serial allocation algorithm, for different frame lengths under 3 different stochastic models. 

\begin{figure}[htbp]
  \centering
    \includegraphics[width=0.7\textwidth]{./Chapter5_Figures/serial_decentral_DQSI_EQSI_UniPoiss_copy.eps}
    \rule{35em}{0.5pt}
  \caption[Decentralized Serial allocation with DQSI and EQSI average latency under uniform Poisson]{Average latency curves under uniform Poisson traffic with increasing injection rate for decentralized serial allocation with DQSI and EQSI algorithm.}
  \label{fig:Electron}
\end{figure}


\begin{figure}[htbp]
  \centering
    \includegraphics[width=0.7\textwidth]{./Chapter5_Figures/serial_decentral_DQSI_EQSI_NonuniPoiss_copy.eps}
    \rule{35em}{0.5pt}
  \caption[Decentralized Serial DQSI and EQSI allocation average latency under non-uniform Poisson]{Average latency curves under non-uniform Poisson traffic with increasing injection rate for decentralized serial allocation with DQSI and EQSI algorithm.}
  \label{fig:Electron}
\end{figure}


\begin{figure}[htbp]
  \centering
    \includegraphics[width=0.7\textwidth]{./Chapter5_Figures/serial_decentral_DQSI_EQSI_DPBPP_copy.eps}
    \rule{35em}{0.5pt}
  \caption[Decentralized Serial DQSI and EQSI allocation average latency under non-uniform DPBPP]{Average latency curves under non-uniform DPBPP traffic with increasing injection rate for decentralized serial allocation with DQSI and EQSI algorithm.}
  \label{fig:Electron} 
\end{figure}

Evaluating Fig. 5.17, Fig. 5.18 and Fig. 5.19 and comparing them to simple regular serial allocation, the most remarkable outcome is to see the substantial average latency decrease by just utilizing DQSI. It is not only eliminating the unnecessary resource allocation, but also compensates the unfairness due to small number of RBs. For instance, comparing Fig. 5.8 and Fig. 5.22, we see that for plain serial allocation algorithm with a frame length of 4 symbols, queues blow up for injection rates higher than 7 packets/symbol, whereas DQSI based allocation can still provide average latency smaller than 10 symbols, for injection rates up to 10 packets/symbol. We see that for this case, EQSI provides a capacity around up to 9 packets/symbol. 

The main motivation behind DQSI's strong improvement lies at its ability to avoid redundant service allocation, thus making sure only highly loaded queues gets their appropriate share from bandwidth. Apparently, it is even providing better fairness under these evaluated scenarios than 2-loop allocation mechanism. DQSI encoding requires only a single subtraction operation before broadcast of QSIs, which can be performed in a single cycle. In addition default allocation matrix mechanism, makes sure the non-utilized RBs are evenly arbitrated among all tilesets.


As expected, as frame gets longer, EQSI provides much better results compared to DQSI. However note that, DQSI just only require a single cycle subtraction operation which makes it feasible for short frame lengths such as 4 symbols.

\textit{Packet Delay and Queue Length Bound Exceeding Probabilities}


Next, we evaluate the queue length and packet delay exceeding probability graphs for DQSI and EQSI under non-uniform DPBPP traffic. 

 \begin{figure*}[htbp]
  \centering
  \begin{tabular}[c]{cccc}

  \subcaptionbox{}[.5\linewidth][]{%
    \includegraphics[width=0.48\textwidth, height =0.4\textwidth]{./Chapter5_Figures/serial_decentral_DQSI_EQSI_DPBPP_delayOverflow_copy.eps} }	
    
  \subcaptionbox{}[.5\linewidth][]{%
    \includegraphics[width=0.48\textwidth, height =0.4\textwidth]{./Chapter5_Figures/serial_decentral_DQSI_EQSI_DPBPP_queueOverflow_copy.eps}}
 
   \end{tabular}

  \caption{Packet Delay (a) and Queue Length (b) exceeding probability graphs for decentralized serial allocation with DQSI and EQSI algorithm under non-uniform DPBPP traffic (log-linear)}
\end{figure*}


Evaluating Fig. 5.20(a), we see the strong performance of DQSI in terms of minimizing delay exceeding probability. For delay bounds larger than 40 symbols, the probability of exceeding with DQSI for T=4, T=8, and T=16 follows practically the curve. Comparing DQSI to 2-loop algorithm (Fig. 5.12), we see the dramatic performance augmentation. For instance, with T=4 symbols of frame length, the probability of having a packet delay larger than 10 symbols for decentralized DQSI algorithm (both frequency and time direction) is around 0.1 while for decentralized 2-loop allocation it is around 0.8. We do not observe the same performance extension for queue length exceeding probabilities. Even though, for small queue length bounds probabilities are smaller for DQSI compared to 2-loop extension, for instance probability of a queue length to exceed 90 flits is practically the same. 

Another result from Fig. 5.20(a) signifies that EQSI provides lesser delay exceeding probability (for delay bounds smaller than 80 symbols), compared to DQSI, with a frame length of 32 symbols. This is quite convenient as, with larger frames, QSI gets outdated more severly and the average input traffic has to be included in the allocation procedure. However, recall that, DQSI requires only a subtraction operation before QSI encoding, which makes it viable for short frame lengths.

\subsubsection{Centralized Approach}
In this section, centralized version of the DQSI and EQSI extension is evaluated with 2 symbols of additional reconfiguration delay and extra overhead for responses. As mentioned in Section 4.3.3.7, tilesets only broadcast their instantaneous QSI every frame, whereas CIU keeps the number of RBs of allocated in previous frame, QSIs reported in previous frame for each tileset, moving averages and computes the DQSI and EQSI. 

\textit{Average Latency}


The average delay with increasing injection rate and probability graphs for delay bound and queue length bound exceeding probabilities are examined to check whether a subtle degradation occurs due to centralization. 

\begin{figure}[htbp]
  \centering
    \includegraphics[width=0.7\textwidth]{./Chapter5_Figures/serial_central_DQSI_EQSI_UniPoiss_copy.eps}
    \rule{35em}{0.5pt}
  \caption[Centralized Serial allocation with DQSI and EQSI average latency under uniform Poisson]{Average latency curves under uniform Poisson traffic with increasing injection rate for centralized serial allocation with DQSI and EQSI algorithm.}
  \label{fig:Electron}
\end{figure}


\begin{figure}[htbp]
  \centering
    \includegraphics[width=0.7\textwidth]{./Chapter5_Figures/serial_central_DQSI_EQSI_NonuniPoiss_copy.eps}
    \rule{35em}{0.5pt}
  \caption[Centralized Serial DQSI and EQSI allocation average latency under non-uniform Poisson]{Average latency curves under non-uniform Poisson traffic with increasing injection rate for centralized serial allocation with DQSI and EQSI algorithm.}
  \label{fig:Electron}
\end{figure}


\begin{figure}[htbp]
  \centering
    \includegraphics[width=0.7\textwidth]{./Chapter5_Figures/serial_central_DQSI_EQSI_DPBPP_copy.eps}
    \rule{35em}{0.5pt}
  \caption[Centralized Serial DQSI and EQSI allocation average latency under non-uniform DPBPP]{Average latency curves under non-uniform DPBPP traffic with increasing injection rate for centralized serial allocation with DQSI and EQSI algorithm.}
  \label{fig:Electron} 
\end{figure} 


By comparing Fig. 5.17, Fig. 5.18 and Fig. 5.19 with Fig. 5.21, Fig. 5.22 and Fig. 5.23 respectively, we do not observe any intense increase in average latency (except few symbols) or any observable pattern change. Therefore, we can claim if DQSI or EQSI based serial allocation would be implemented, a centralized approach can be taken to decrease the computational complexity at the tileset front-ends. Similarly as for the decentralized case, EQSI provides much better performance especially for larger frame lengths. 

\pagebreak

\textit{Packet Delay and Queue Length Bound Exceeding Probabilities}


Delay bound and queue length bound exceeding probability graphs are also evaluated for the centralized DQSI or EQSI based serial QSI allocation, under non-uniform DPBPP traffic with a total injection rate of 10 packets/symbol.   


 \begin{figure*}[htbp]
  \centering
  \begin{tabular}[c]{cccc}

  \subcaptionbox{}[.5\linewidth][]{%
    \includegraphics[width=0.48\textwidth, height =0.4\textwidth]{./Chapter5_Figures/serial_central_DQSI_EQSI_DPBPP_delayOverflow_copy.eps}}	
    
  \subcaptionbox{}[.5\linewidth][]{%
    \includegraphics[width=0.48\textwidth, height =0.4\textwidth]{./Chapter5_Figures/serial_central_DQSI_EQSI_DPBPP_queueOverflow_copy.eps}}
 
   \end{tabular}

  \caption{Packet Delay (a) and Queue Length (b) exceeding probability graphs for centralized serial allocation algorithm with DQSI and EQSI under non-uniform DPBPP traffic (log-linear)}
\end{figure*}

We see in Fig. 5.24, that probability of exceeding delay bounds (especially small delay bounds such as 10-20 symbols) is slightly larger for centralized approach both for DQSI and EQSI, especially for the small frame lengths (4-8 symbols), which is an expected outcome. Besides this small performance degradation, centralized and decentralized DQSI or EQSI shows close performance under these circumstances, which may be a good reason to choose centralized version of it to concentrate computational power in a single part of the CMP.

\section{Queue Proportional Allocation}

\subsection{Regular Queue Proportional Allocation}

In previous section (5.1), we have proposed and examined the feasibility of possibly the simplest option, serial QSI allocation algorithm, where tilesets broadcast their instantaneous QSI and RBs iniside a frame are arbitrated sequentially in a single loop. The major motivation behind this kind of a practice is to be able to effectuate allocation operation in few hundreds of nanoseconds including all other extra cumulative delays stemming from propagation, synchronization, processing etc., which is a strict constraint imposed by the 20 GHz OFDMA interconnect and on-chip environment. On-chip packets demand delays as low as possible, tens of nanoseconds. Allocating RBs in a single loop can also be performed in small frame lengths, thus more and more up-to-date QSIs, which shall enhance the performance further. However, we have observed that this simple allocation pattern is not suitable to approach the capacity of the system, contradictory for smaller frame lengths, due to the starvation of all RBs in a frame by certain nodes. We were able to augment the performance of this algorithm by adding a second iteration. However, we have seen that most of the performance from this algorithm can be gained through using DQSI with small frame lengths such as 4 or 8 symbols. 


In this section, we evaluate the viability of the Queue Proportional Scheduling (QPS) algorithm with additional limited complexity compared to serial allocation. The main idea is to allocate RBs in a frame proportionally to QSIs of the tilesets. 

Formally, these operations can be written as :

\begin{align}
S_{i}^{t+1} = \left\lceil N{{Q}_{i}^{t} \over \sum\limits_{j=1}^K {Q}_{j}^{t}}\right\rceil
\end{align} 

where N is the number of RBs, K is the number of tilesets and $S_{i}^{t+1}$ is the number of RBs allocated to tileset $i$ in next frame. Note that, as the resulting ratio can be a fractional, it is always upper rounded. By this way, first we make sure that even a node with a QSI of 1 would be allocated a RB (thus preventing starvation) and second we avoid any RB left unassigned (therefore, there is no notion of default allocation matrix for as in previous serial allocation algorithm). However, one can see that, this would cause the calculated total number of RBs to exceed the total available number of RBs, N. This is simply resolved by the sequential RB allocation through a frame in time or frequency direction, just as in the previous section. This time, rather than using directly the emitted QSI values, recently calculated $S_{i}^{t+1}$ values are taken from tilesets in a loop, and RBs are allocated as for the serial allocation algorithm. Hence, allocation terminates when there is no RBs left to assign. One can see that, the tilesets which are sequenced last may have a certain degree of disadvantage. Therefore, just as in the serial allocation algorithm a simple rotating priority mechanism is employed. 

Another important point to highlight is on the computational complexity of the algorithm. First, QSIs of K (32 for our case) tilesets are summed. In case of 8 bits encoding is preferred as evaluated in this thesis work, for 32 tilesets, this operation yields to a 13-bit summation. Hence, 16 bit simple processors can be used, or in case of using 32 or 64 bit processor(s), summation can be performed in parallel, thus in lesser time.  As can be seen in  equation (5.1), the division of N and QSI summation is multiplied by the QSI of each tileset, therefore this value can be calculated once and kept in a register, and utilized repeatedly. This shall save a significant amount of computation time. At the end, there is one division operation (minimum 13-bits with 8-bit QSI), 32 summations and 32 multiplications. Multiplications and divisions can be performed in fixed point manner as numerical accuracy is not a problem for this specific allocation, which would ease further the task of the RB allocation processor(s).

\textbf{\textit{Optimality  Issue of Queue Proportional Scheduling}}

In Section 4.2.3, while reviewing the literature for rate scheduling, we have mentioned about the arbitration of bandwidth among multiple parallel queues proportional to square root of their QSIs. This was the solution to an optimization problem intending to solve the \textquotedblleft minimum draining time\textquotedblright, i.e. to minimize the time required to clear out a vector of K queues, by allocating the appropriate fraction of the whole rate (bandwidth) :

\begin{align}
arg min  \left\{ \frac{Q_{1}}{r_{1}} + \,  ... \, + \frac{Q_{K}}{r_{K}} \right\} \, \, s.t., \, \, \sum\limits_{i=1}^K r_{i} = R
\end{align} 

This problem intends to minimize the total draining time of the queues, whereas we are more interested in minimizing the total delays experienced by packets in these parallel queues. Consider this illustrative simple example that a queue has P packets at $t=0$ and it has a constant service rate of 1 packet/slot. The draining time for the queue is obviously P slots. In contrast, the individual delays for each packet is 1 slot for the first packet served, 2 slots for the second packet served, ... , and P slots for the last packet served, due to waiting time for service. Hence, at the end total (or average if divided by the total number of packets) delay experienced by all packets, $D_{total}$ is :

\begin{align}
D_{total} = \sum \limits_{i=1}^{P} i = \frac{P(P+1)}{2}
\end{align}

In a nutshell, we observe a cumulative effect for total delay experienced by packets with the instantaneous number of packets in a queue. By looking at the above equation, we understand that total (average) delay for the packets in a queue is related with the square of the instantaneous queue state. 

Returning back to the equation (5.2), for the minimization of the draining time, we can reformulate this equation loosely to minimize the \textquotedblleft square of the QSIs\textquotedblright, for minimizing average packet delay. As solution to the previous problem is to divide the total rate proportionally to the square root of QSIs, the solution to the new problem is simply to divide the total rate proportional to the instantaneous QSIs. 

\subsubsection{Decentralized Approach}

First, decentralized version of the QPS algorithm is evaluated, where each tileset execute the same operation to arbitrate RBs in a frame, proportional to broadcasted QSI values. RBs are assigned both in frequency and time direction. As for the previously proposed serial QSI allocation algorithm, identical experiments and traffic models are evaluated. 

\textit{Average Latency}


\begin{figure}[htbp]
  \centering
    \includegraphics[width=0.7\textwidth]{./Chapter5_Figures/QPS_decentral_plain_UniPoiss_copy.eps}
    \rule{35em}{0.5pt}
  \caption[Decentralized QPS Allocation Average latency under uniform Poisson]{Average latency curves under uniform Poisson traffic with increasing injection rate for decentralized QPS allocation algorithm.}
  \label{fig:Electron}
\end{figure}

\begin{figure}[htbp]
  \centering
    \includegraphics[width=0.7\textwidth]{./Chapter5_Figures/QPS_decentral_plain_NonuniPoiss_copy.eps}
    \rule{35em}{0.5pt}
  \caption[Decentralized QPS Allocation Average latency under non-uniform Poisson]{Average latency curves under non-uniform Poisson traffic with increasing injection rate for decentralized QPS allocation algorithm.}
  \label{fig:Electron}
\end{figure}


\begin{figure}[htbp]
  \centering
    \includegraphics[width=0.7\textwidth]{./Chapter5_Figures/QPS_decentral_plain_DPBPP_copy.eps}
    \rule{35em}{0.5pt}
  \caption[Decentralized QPS Allocation Average latency under non-uniform DPBPP]{Average latency curves under non-uniform DPBPP traffic with increasing injection rate for decentralized QPS allocation algorithm.}
  \label{fig:Electron}
\end{figure}
 

First thing we notice in these average latency curves is the remarkably high average latency under low injection rates, especially for longer frame lengths. Comparing these figures (Fig. 5.25, Fig. 5.26 and Fig. 5.27) to serial QSI allocation, we do not observe this high latency offset for low injection rates. This effect roots from the nature of QPS. If a tileset has zero QSI at the start of a frame, it will be allocated no RBs during the whole next frame, as allocation is done proportional to QSIs. Due to the pipelined allocation, if a packet arrives to an idle queue, it has to wait until the start of next frame to get a share of the total bandwidth. However, in regular serial QSI allocation, as we have mentioned, there exists the notion of \textquotedblleft default frame allocation\textquotedblright, which arbitrates unassigned RBs evenly among all 32 tilesets. Thus, even a tileset has zero QSI, it will be allocated certain amount of RBs, which avoids this phenomenon. Note that, obviously this effect gets more evident under lower injection rates.

In contrast, QPS provides a much better performance for larger injection rates, especially near system capacity compared to serial allocation (without any modification). Because, naturally allocating RBs proportionally to QSIs, eliminates the probability that certain nodes to exhaust all the RBs in a frame and starve other nodes. 

From these figures, we observe that, QPS algorithm can approach to near the system limit even without any modification. Especially for small frame lengths, we observe that QPS provides reasonably low average latencies.

\textit{Packet Delay and Queue Length Bound Exceeding Probabilities}


As a next step, packet delay bound and queue length exceeding probability graphs are evaluated under non-uniform DPBPP traffic with an injection rate of 10 packets/symbol.

 
\begin{figure*}[htbp]
  \centering
  \begin{tabular}[c]{cccc}

  \subcaptionbox{}[.5\linewidth][]{%
    \includegraphics[width=0.48\textwidth, height =0.4\textwidth]{./Chapter5_Figures/QPS_decentral_plain_DPBPP_delayOverflow_copy.eps} }	
    
  \subcaptionbox{}[.5\linewidth][]{%
    \includegraphics[width=0.48\textwidth, height =0.4\textwidth]{./Chapter5_Figures/QPS_decentral_plain_DPBPP_queueOverflow_copy.eps}}
 
   \end{tabular}

  \caption{Packet Delay (a) and Queue Length (b) exceeding probability graphs for decentralized QPS allocation algorithm under non-uniform DPBPP traffic (log-linear)}
\end{figure*}

\subsubsection{Centralized Approach}

In centralized version of the QPS algorithm, calculation of RBs proportional to QSIs are performed by the CIU and based on the response messages, bandwidth is reconfigured with 2 symbol latency as for the serial allocation algorithm. 

\textit{Average Latency}


\begin{figure}[htbp]
  \centering
    \includegraphics[width=0.7\textwidth]{./Chapter5_Figures/QPS_central_plain_UniPoiss_copy.eps}
    \rule{35em}{0.5pt}
  \caption[Centralized QPS Allocation Average latency under uniform Poisson]{Average latency curves under uniform Poisson traffic with increasing injection rate for centralized QPS allocation algorithm.}
  \label{fig:Electron}
\end{figure}

\begin{figure}[htbp]
  \centering
    \includegraphics[width=0.7\textwidth]{./Chapter5_Figures/QPS_central_plain_NonuniPoiss_copy.eps}
    \rule{35em}{0.5pt}
  \caption[Centralized QPS Allocation Average latency under non-uniform Poisson]{Average latency curves under non-uniform Poisson traffic with increasing injection rate for centralized QPS allocation algorithm.}
  \label{fig:Electron}
\end{figure}


\begin{figure}[htbp]
  \centering
    \includegraphics[width=0.7\textwidth]{./Chapter5_Figures/QPS_central_plain_DPBPP_copy.eps}
    \rule{35em}{0.5pt}
  \caption[Centralized QPS Allocation Average latency under non-uniform DPBPP]{Average latency curves under non-uniform DPBPP traffic with increasing injection rate for centralized QPS allocation algorithm.}
  \label{fig:Electron}
\end{figure}


Fig. 5.29, Fig. 5.30 and Fig. 5.31 show the slight increase in average latencies with centralizing the algorithm due to extra latency and signaling overhead, however performance patterns are similar with the decentralized case. 

\pagebreak

\textit{Packet Delay and Queue Length Bound Exceeding Probabilities}

Next, we evaluate the packet delay and queue length exceeding probability graphs for centralized QPS algorithm. The slight performance degradation due to centralization can be observed in Fig. 5.32.

\begin{figure*}[htbp]
  \centering
  \begin{tabular}[c]{cccc}

  \subcaptionbox{}[.5\linewidth][]{%
    \includegraphics[width=0.48\textwidth, height =0.4\textwidth]{./Chapter5_Figures/QPS_central_plain_DPBPP_delayOverflow_copy.eps} }	
    
  \subcaptionbox{}[.5\linewidth][]{%
    \includegraphics[width=0.48\textwidth, height =0.4\textwidth]{./Chapter5_Figures/QPS_central_plain_DPBPP_queueOverflow_copy.eps}}
 
   \end{tabular}

  \caption{Packet Delay (a) and Queue Length (b) exceeding probability graphs for centralized QPS allocation algorithm under non-uniform DPBPP traffic (log-linear)}
\end{figure*}


\subsection{QPS Allocation with DQSI and EQSI}

We seek to increase the performance of QPS algorithm by using DQSI or EQSI encoding especially for small injection rates. As for the previous cases, decentralized and centralized version of DQSI and EQSI differs. 

\pagebreak

\subsubsection{Decentralized Approach}
\textit{Average Latency}


First, we investigate the average latency with increasing injection rate for decentralized QPS with DQSI and EQSI under different traffic models. 

\begin{figure}[htbp]
  \centering
    \includegraphics[width=0.7\textwidth]{./Chapter5_Figures/QPS_decentral_DQSI_EQSI_UniPoiss_copy.eps}
    \rule{35em}{0.5pt}
  \caption[Decentralized QPS allocation with DQSI and EQSI average latency under uniform Poisson]{Average latency curves under uniform Poisson traffic with increasing injection rate for decentralized QPS allocation with DQSI and EQSI algorithm.}
  \label{fig:Electron}
\end{figure}


\begin{figure}[htbp]
  \centering
    \includegraphics[width=0.7\textwidth]{./Chapter5_Figures/QPS_decentral_DQSI_EQSI_NonuniPoiss_copy.eps}
    \rule{35em}{0.5pt}
  \caption[Decentralized QPS DQSI and EQSI allocation average latency under non-uniform Poisson]{Average latency curves under non-uniform Poisson traffic with increasing injection rate for decentralized QPS allocation with DQSI and EQSI algorithm.}
  \label{fig:Electron}
\end{figure}


\begin{figure}[htbp]
  \centering
    \includegraphics[width=0.7\textwidth]{./Chapter5_Figures/QPS_decentral_DQSI_EQSI_DPBPP_copy.eps}
    \rule{35em}{0.5pt}
  \caption[Decentralized QPS DQSI and EQSI allocation average latency under non-uniform DPBPP]{Average latency curves under non-uniform DPBPP traffic with increasing injection rate for decentralized QPS allocation with DQSI and EQSI algorithm.}
  \label{fig:Electron} 
\end{figure}

In Fig. 5.33, Fig. 5.34 and Fig. 5.35, we see that average latencies are significantly lowered with EQSI or DQSI for small injection rates. Arbitrating bandwidth proportionally to expected QSIs allow the allocation of resources for nodes who are likely to have packets in their queues on next frame. 

Another important remark for QPS algorithm is on the direction of allocation. We observe that for most of the cases, assigning RBs in time direction is much better than frequency direction. In serial allocation, this was the reverse. This is due to the fact that, in serial allocation not all of the RBs are allocated but just the total demand of all tilesets. And the rest was divided evenly among tilesets. Therefore, serving all demands in few symbols by allocating them in frequency direction was more favorable. However, in QPS all of the RBs are always allocated proportional to QSIs of non-idle queues. Hence, allocation in time direction, which allows for a more temporally uniform pattern, is better for QPS algorithm. 

\textit{Packet Delay and Queue Length Bound Exceeding Probabilities}


Following this, we investigate the packet delay bound and queue length exceeding probability graphs for decentralized QPS algorithm with DQSI and EQSI encoding under DPBPP traffic, with 10 packets/symbol injection rate. 

\begin{figure*}[htbp]
  \centering
  \begin{tabular}[c]{cccc}

  \subcaptionbox{}[.5\linewidth][]{%
    \includegraphics[width=0.48\textwidth, height =0.4\textwidth]{./Chapter5_Figures/QPS_decentral_DQSI_EQSI_DPBPP_delayOverflow_copy.eps} }	
    
  \subcaptionbox{}[.5\linewidth][]{%
    \includegraphics[width=0.48\textwidth, height =0.4\textwidth]{./Chapter5_Figures/QPS_decentral_DQSI_EQSI_DPBPP_queueOverflow_copy.eps}}
 
   \end{tabular}

  \caption{Packet Delay (a) and Queue Length (b) exceeding probability graphs for decentralized QPS allocation algorithm under non-uniform DPBPP traffic (log-linear)}
\end{figure*}


Among the serial QSI algorithms, best performance was shown by the DQSI encoded allocation with the lowest frame length of 4 symbols. Comparing Fig. 5.23 with Fig. 5.35, we see that QPS allocation with DQSI encoding with 4 symbols frame length provides nearly the same performance. However, for longer frame lenghts, EQSI encoded frame lengths perform better compared to serial allocation algorithm. One may ask, what is the purpose of introducing more computational complexity by employing QPS algorithm, rather than serial allocation, if it provides the same performance for the small frame lengths. However, we have observed that QPS algorithms is also capable to provide better performance. In addition, it provides better performance than serial allocation for delay bound and queue length exceeding probabilities under certain circumstances. 

Let us compare serial allocation with DQSI to the secondly proposed QPS algorithm. Under non-uniform DPBPP traffic, for the average latencies we see that best one is DQSI encoded serial allocation with T=4 (both in frequency and time direction) (Fig. 5.19) which shows actually the same performance with DQSI encoded QPS with T=4 symbols. However, we observe difference up to a degree for delay and queue length exceeding probabilities for two different algorithms. For instance, probability of a packet exceeding a delay of 60 symbols is approximately $10^{-3}$ for DQSI encoded QPS with T=4 (Fig. 5.36(a)), whereas for DQSI encoded serial allocation with T=4 is approximately $10^{-2}$ (Fig. 5.20(a)). Similarly, exceeding an instantaneous queue length of 90 is approximately $10^{-4}$ for DQSI encoded QPS with T=4 (Fig. 5.36(b)), whereas for DQSI encoded serial allocation with T=4 is approximately $10^{-3}$ (Fig. 5.20(b)). We can claim that even though average latency performances are equal, delay and queue length exceeding performance of QPS may be remarkably higher than serial allocation. Besides, apart from scenarios covered in this thesis, QPS algorithm shall provide a more reliable performance in most of the cases compared to serial allocation, as it proportionally divides the bandwidth. Despite its additional computational complexity, a designer may choose QPS over DQSI encoded serial allocation, where both options may be optimal depending on the situation.

\subsubsection{Centralized Approach}
\textit{Average Latency}


Following this, centralized version of DQSI and EQSI encoding enhanced QPS algorithm is evaluated. Fig. 5.37, Fig. 5.38 and Fig. 5.39 shows the average latency with increasing injection rate under 3 different traffic models. We observe a very slight but not evident performance degradation for centralization.



\begin{figure}[htbp]
  \centering
    \includegraphics[width=0.7\textwidth]{./Chapter5_Figures/QPS_central_DQSI_EQSI_UniPoiss_copy.eps}
    \rule{35em}{0.5pt}
  \caption[Centralized QPS allocation with DQSI and EQSI average latency under uniform Poisson]{Average latency curves under uniform Poisson traffic with increasing injection rate for centralized QPS allocation with DQSI and EQSI algorithm.}
  \label{fig:Electron}
\end{figure}


\begin{figure}[htbp]
  \centering
    \includegraphics[width=0.7\textwidth]{./Chapter5_Figures/QPS_central_DQSI_EQSI_NonuniPoiss_copy.eps}
    \rule{35em}{0.5pt}
  \caption[Centralized QPS DQSI and EQSI allocation average latency under non-uniform Poisson]{Average latency curves under non-uniform Poisson traffic with increasing injection rate for centralized QPS allocation with DQSI and EQSI algorithm.}
  \label{fig:Electron}
\end{figure}


\begin{figure}[htbp]
  \centering
    \includegraphics[width=0.7\textwidth]{./Chapter5_Figures/QPS_central_DQSI_EQSI_DPBPP_copy.eps}
    \rule{35em}{0.5pt}
  \caption[centralized QPS DQSI and EQSI allocation average latency under non-uniform DPBPP]{Average latency curves under non-uniform DPBPP traffic with increasing injection rate for centralized QPS allocation with DQSI and EQSI algorithm.}
  \label{fig:Electron} 
\end{figure}

\pagebreak

\textit{Packet Delay and Queue Length Bound Exceeding Probabilities}



And lastly, packet delay bound and queue length bound exceeding probabilities are shown in following figures. 

\begin{figure*}[htbp]
  \centering
  \begin{tabular}[c]{cccc}

  \subcaptionbox{}[.5\linewidth][]{%
    \includegraphics[width=0.48\textwidth, height =0.4\textwidth]{./Chapter5_Figures/QPS_central_DQSI_EQSI_DPBPP_delayOverflow_copy.eps} }	
    
  \subcaptionbox{}[.5\linewidth][]{%
    \includegraphics[width=0.48\textwidth, height =0.4\textwidth]{./Chapter5_Figures/QPS_central_DQSI_EQSI_DPBPP_queueOverflow_copy.eps}}
 
   \end{tabular}

  \caption{Packet Delay (a) and Queue Length (b) exceeding probability graphs for centralized QPS allocation algorithm with DQSI and EQSI under non-uniform DPBPP traffic (log-linear)}
\end{figure*}

\section{Implementation of Algorithms}

As we have designed RF controller in software executed on a dedicated tile of each tileset, all allocation algorithms can be implemented in a software way. We propose here the algorithm view to be programmed in order to implement our proposals. 


Fig. 5.41 depicts the decentralized allocation scheme from a view of a single tileset, for serial or QPS allocation, with regular, definitive or expected QSI encoding. On the first symbol of each frame, a tileset acquires the QSI of other tilesets on the pre-defined subcarriers. If it is a serial allocation, these acquired QSI values are not treated further, and the allocation algorithm starts. However, if QPS is preferred, first the summation of all QSI values is computed. Then the value of the division of total number of RBs, $N$ is divided with this total QSI value and stored temporarily. Using this, proportionally allocated number of RBs for each tileset are calculated, by upper rounding the results. Next, starting from the rotating priority ID tileset, and using the default allocation matrix, RBs are allocated to these calculated values of tileset in a loop, until all the RBs are exhausted, or all tilesets are served. At the end of the frame, tileset reconfigure their transmissions according to this computation, and broadcast their QSIs for next frame. If definitive QSI encoding is chosen; they broadcast the difference between current number of flits in transmission queue and the currently allocated number of RBs (minimal value can be 0). If expected QSI encoding is chosen; they also calculate the moving average value of the mean arrivals by using the number of flits has arrived in last frame; and broadcast the expected QSI values. 


\begin{figure}[htbp]
  \centering
    \includegraphics[width=0.7\textwidth]{./Figures/Decentralized_FlowChart.pdf}
    \rule{35em}{0.5pt}
  \caption[Flow-chart of decentralized subcarrier arbitration algorithms of serial or QPS with regular, definitive or expected QSI encoding.]{Flow-chart of decentralized subcarrier arbitration algorithms of serial or QPS with regular, definitive or expected QSI encoding.} 
  \label{fig:Electron}
\end{figure}

Fig. 5.42 depicts a similar flow-chart for the centralized approach from the view of the Central Intelligent Unit. On the first symbol of each frame, the CIU acquires QSIs from tilesets on the reserved subcarriers. However, this time CIU is responsible of calculating DQSI or EQSI, in contrast the local computation in decentralized approach. Then the allocation is performed and the responses are broadcasted to tilesets. 

\begin{figure}[htbp]
  \centering
    \includegraphics[width=0.7\textwidth]{./Figures/Centralized_FlowChart.pdf}
    \rule{35em}{0.5pt}
  \caption[Flow-chart of centralized subcarrier arbitration algorithms of serial or QPS with regular, definitive or expected QSI encoding.]{Flow-chart of centralized subcarrier arbitration algorithms of serial or QPS with regular, definitive or expected QSI encoding.} 
  \label{fig:Electron}
\end{figure}

\section{Classification of Bandwidth Allocation Algorithms}

Fig. 5.43 depicts the classification of mentioned radio resource allocation in WiNoCoD, with a tree diagram. It gives a global view of the proposed algorithms in the right side, and also the possible static approaches as mentioned in Section 4.3 on the left side. Note that, Chapter 5 only dealt with a single transmission queue where both long and short packets are treated in common flits. In Chapter 6, we will present a new dual queue approach in order to improve the previous algorithms, where a seperate queue buffers payloads of long packets. This type of algorithms are shown in gray in Fig. 5.43. 

\begin{figure}[htbp]
  \centering
    \includegraphics[height=0.75\textwidth, angle =90]{./Chapter5_Figures/radio_resource_alloc.pdf}
    \rule{35em}{0.5pt}
  \caption[Classification of the proposed algorithms for dynamic bandwidth allocation for OFDMA RF NoC.]{Classification of the proposed algorithms for dynamic bandwidth allocation for OFDMA RF NoC.} 
  \label{fig:Electron}
\end{figure}

\section{Comparison of Bandwidth Allocation Algorithms}


In Table 5.2, we compare these 6 different bandwidth allocation algorithms under non-uniform DPBPP traffic, for frame lengths of 8 and 32 symbols (representing a short and long frame) and for total injection rates of 4, 10, 10.6 packets/symbol (representing medium, high and extreme traffic load). We see that, serial allocation with DQSI is the best, except for the frame length of 8 symbols and injection rate of 10.6 packets/symbol. This is thanks to efficient mechanism of default allocation matrix partition while total demand is lower than the total number of RBs and the fair allocation with DQSI. Eventhough serial allocation requires the lowest computational power, it is better in terms of average latency. However, note that, QPS can provide much better performance in terms of queue length or packet delay exceeding probabilities, especially under high traffic load.



\begin{table}[b!]
\centering
\caption{Average latencies (in symbols) of 6 presented algorithms for various frame lengths and injection rates, under non-uniform DPBPP traffic. For each of the algorithm and the configuration, best direction of allocation is chosen and labeled as (f) \textit{frequency} or (t) \textit{time}.}
\label{my-label}
\begin{adjustbox}{width=1\textwidth}
\begin{tabular}{lllllll}
\cline{2-7}
\multicolumn{1}{l|}{}                                                                        & \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}Serial \\ Allocation\end{tabular}} & \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}Serial \\ Allocation \\ with DQSI\end{tabular}} & \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}Serial \\ Allocation \\ with EQSI\end{tabular}} & \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}QPS\\ Allocation\end{tabular}} & \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}QPS\\ Allocation\\ with DQSI\end{tabular}} & \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}QPS\\ Allocation\\ with EQSI\end{tabular}} \\ \cline{2-7} 
\textit{\textbf{\begin{tabular}[c]{@{}l@{}}T = 8\\ symbols\end{tabular}}}                    &                                                                                   &                                                                                                &                                                                                                &                                                                               &                                                                                           &                                                                                           \\ \hline
\multicolumn{1}{|l|}{\begin{tabular}[c]{@{}l@{}}Inj. Rate =\\ 4 pkts/symbol\end{tabular}}    & \multicolumn{1}{l|}{8.35 (f)}                                                     & \multicolumn{1}{l|}{7.8 (f)}                                                                   & \multicolumn{1}{l|}{7.7 (f)}                                                                   & \multicolumn{1}{l|}{9.1 (t)}                                                  & \multicolumn{1}{l|}{9.1 (t)}                                                              & \multicolumn{1}{l|}{6.2 (t)}                                                              \\ \hline
\multicolumn{1}{|l|}{\begin{tabular}[c]{@{}l@{}}Inj. Rate =\\ 10 pkts/symbol\end{tabular}}   & \multicolumn{1}{l|}{$\infty$}                                                     & \multicolumn{1}{l|}{15.6 (f)}                                                                  & \multicolumn{1}{l|}{79.9 (t)}                                                                  & \multicolumn{1}{l|}{18.8 (t)}                                                 & \multicolumn{1}{l|}{15.3 (t)}                                                             & \multicolumn{1}{l|}{18.2 (t)}                                                             \\ \hline
\multicolumn{1}{|l|}{\begin{tabular}[c]{@{}l@{}}Inj. Rate =\\ 10.6 pkts/symbol\end{tabular}} & \multicolumn{1}{l|}{$\infty$}                                                     & \multicolumn{1}{l|}{29.8 (f)}                                                                  & \multicolumn{1}{l|}{$\infty$}                                                                  & \multicolumn{1}{l|}{28.7 (t)}                                                 & \multicolumn{1}{l|}{24.3 (t)}                                                             & \multicolumn{1}{l|}{32.4 (t)}                                                             \\ \hline
\textit{\textbf{\begin{tabular}[c]{@{}l@{}}T = 32\\ symbols\end{tabular}}}                   &                                                                                   &                                                                                                &                                                                                                &                                                                               &                                                                                           &                                                                                           \\ \hline
\multicolumn{1}{|l|}{\begin{tabular}[c]{@{}l@{}}Inj. Rate =\\ 4 pkts/symbol\end{tabular}}    & \multicolumn{1}{l|}{14.8 (f)}                                                     & \multicolumn{1}{l|}{7.6 (f)}                                                                   & \multicolumn{1}{l|}{7.8 (f)}                                                                   & \multicolumn{1}{l|}{29.4 (t)}                                                 & \multicolumn{1}{l|}{31.9 (t)}                                                             & \multicolumn{1}{l|}{18.7 (t)}                                                             \\ \hline
\multicolumn{1}{|l|}{\begin{tabular}[c]{@{}l@{}}Inj. Rate =\\ 10 pkts/symbol\end{tabular}}   & \multicolumn{1}{l|}{$\infty$}                                                     & \multicolumn{1}{l|}{16.7 (f)}                                                                  & \multicolumn{1}{l|}{47.3 (f)}                                                                  & \multicolumn{1}{l|}{49.3 (t)}                                                 & \multicolumn{1}{l|}{45.3 (t)}                                                             & \multicolumn{1}{l|}{35.1 (t)}                                                             \\ \hline
\multicolumn{1}{|l|}{\begin{tabular}[c]{@{}l@{}}Inj. Rate =\\ 10.6 pkts/symbol\end{tabular}} & \multicolumn{1}{l|}{$\infty$}                                                     & \multicolumn{1}{l|}{40.3 (f)}                                                                  & \multicolumn{1}{l|}{59.9 (f)}                                                                  & \multicolumn{1}{l|}{65.7 (t)}                                                 & \multicolumn{1}{l|}{53.9 (t)}                                                             & \multicolumn{1}{l|}{46.7 (t)}                                                             \\ \hline
\end{tabular}
\end{adjustbox}
\end{table}

\section{Conclusion}

The primary criterion on the development of bandwidth allocation algorithms for WiNoCoD RF interconnect is low computational complexity. This obligation stems from the very short OFDM symbol duration of 50 ns, where bandwidth arbitration shall be effectuated in few symbol durations. Considering the processing speeds of current semiconductor technology, this time constraint imposes that the proposed allocation algorithm should be executed in few hundreds of ns. Therefore, proposed solutions should avoid large number of iterations and complex operations, but should be implementable with basic mathematical processor operators or Look-up Tables (LUTs). Considering this algorithm execution time and also other delays regarding reconfiguration, a pipelined allocation scheme is adopted for WiNoCoD. However, the latency performance of the algorithms are at the paramount of importance, even though OFDM symbols are short, ironically they are long for the on-chip packets. Hence, saving average delay by few symbols may increase the on-chip performance drastically.




For this purpose, first proposed algorithm was serial QSI allocation algorithm, which practically needs any mathematical operations and lowest number of iterations. However, we have discussed the starvation issue due to certain nodes acquiring all RBs, thus causing an early system fail, especially for short frame lengths. We have tried to mitigate this effect by employing a 2-loop queue balancing mechanism, but the best results for serial allocation algorithm is taken with DQSI encoding. This basic operation avoids the redundant allocation of RBs, and makes sure for a fairer arbitration of the bandwidth. 

Next, we introduce the QPS algorithm, which divides bandwidth among tilesets proportional to their instantaneous QSIs. First thing we observe for the performance of this algorithm is the relatively high average latency for small injection rates. We discuss that this was due to the fact that, when a QSI is 0 for a tileset, it is allocated 0 RBs on that frame, and any newly arrived packet has to wait for the next frame. By employing EQSI and DQSI mechanisms, we are able to mitigate this high average latency under low injection rate. 


DQSI encoded serial QSI allocation provides really good performance, and needs practically the lowest computational complexity. This mechanism is feasible to be implemented with short 4-8 symbols frame lengths. Apart from scenarios covered in this thesis, QPS algorithm shall provide a more reliable performance in most of the cases compared to serial allocation, as it proportionally divides the bandwidth. Despite its additional computational complexity, a designer may choose QPS over DQSI encoded serial allocation, where both options may be optimal depending on the situation.
