% Chapter 0

\chapter{Résumé en Français : Allocation Dynamique de Bande Passante pour l'Interconnexion RF d'un Résau-sur-Puce} % Main chapter title

\label{Chapter0} % For referencing the chapter elsewhere, use \ref{Chapter1} 

\lhead{Chapter 0. \emph{Résumé en Français}} % This is for the header on each page - perhaps a shortened title



\section*{Chapitre 1 : Introduction}

L’accélération des traitements numériques a été portée depuis un demi-siècle par la diminution de la géométrie des transistors, mais cette tendance est dorénavant freinée en raison de problèmes thermiques et lithographiques liés aux dimensions nanométriques actuelles. Par ailleurs, le compromis entre puissance de calcul et consommation a poussé l'utilisation de plusieurs processeurs en parallèle sur une même puce pour exécuter des applications à forte exigence en termes de calculs. Aujourd'hui, il est fréquent de voir des puces avec plusieurs cœurs dans nos téléphones, ordinateurs, serveurs, terminaux ADSL, appareils photo numériques, etc.. En électronique embarquée, on parle de systèmes sur puces (System-on-Chip ou SoC) où les unités sont généralement de natures différentes (hétérogènes). Dans le domaine informatique, cela se traduit par la mise en parallèle de plusieurs voire nombreuses unités de traitement identiques (homogène), comme dans les GPU (Graphical Processing Units), processeurs superscalaires, etc.. Dans un avenir proche, on estime à quelques milliers le nombre de cœurs présents sur une seule puce. Ces systèmes sont appelés généralement avec la dénomination anglaise Chip Multiprocesseurs (CMPs) ou processeurs ManyCore.


Avec l'augmentation du nombre de cœurs dans une même puce, le problème des communications entre les cœurs devient prépondérant. Il est devenu impossible d'implanter des fils dédiés point à point entre tous les coeurs et des problèmes de congestion apparaissent avec les bus conventionnels. Les chercheurs ont introduit un nouveau paradigme connu sous le nom de réseau sur puce (Network-on-Chip ou NoC), où la couche de communication est détachée des coeurs et la transmission entre cœurs est effectuée par paquets via des routeurs, comme dans un réseau. Même si les  NoC ont démontré leur performance en termes de latence et de bande passante, ils atteignent à leur tour des limites à partir de plusieurs dizaines de cœurs. 

Récemment, les interconnexions optiques et radiofréquence (RF) sur puce ont été proposées pour fournir une solution à l’apparition de ce goulot d'étranglement. Ces interconnexions utilisent des ondes électromagnétiques pour transmettre des signaux à des vitesses plus proches de celle de la lumière, à la différence du câblage de cuivre classique utilisé jusqu’ici. Cependant, ces deux architectures, optiques et RF, ont besoin d'implanter des circuits spécialisés dans les émetteurs-récepteurs de chaque noeud (en regroupe plusieurs cœurs entre eux car connecter chaque cœur serait trop complexe) qui a un accès au canal de communication. En raison de la nature statique des architectures d’émission réception jusqu’à présent identifiées dans la littérature, l'allocation dynamique des canaux de communication à différents noeuds, en fonction de leur demande instantanée de bande passante est impossible. Cependant, en raison du trafic très fluctuant généré par les applications entre les cœurs, les approches RF et optiques apportent jusqu’à présent une solution limitée, ou surdimensionnée entre les capacités qu’elles apportent et celles qui peuvent être exploitées effectivement en cours de fonctionnement. 

Afin de remédier à ces limitations, le projet WiNoCoD (Wired RF Network-on-Chip Reconfigurable-on-Demand) a été initié grâce au financement de l'Agence Nationale de Recherche (ANR). Les partenaires du projet sont ETIS-ENSEA, LIP6 -UPMC, NXP Semiconductors et IETR-CentraleSupélec. Ce travail de thèse contribue au projet WiNoCoD. La contribution majeure du projet WiNoCoD pour la communauté scientifique des réseaux-sur-puce est son interconnexion de communication RF basée sur l’OFDMA (Orthogonal Frequency Division Multiplexing Access). Contrairement aux interconnexions sur puce existantes, la modulation OFDM, support de l’OFDMA, permet de générer de nombreux canaux orthogonaux grâce à un nombres de circuits analogiques réduit (non pas une chaîne RF à bande étroite par canal, mais une seule chaîne RF globale à large bande). En outre, l’encodage des données sur les canaux de fréquences orthogonales est une procédure purement numérique en OFDM et sa capacité intrinsèque de diffusion est un atout très important en raison des caractéristiques particulières du trafic des données dans un réseau sur puce.

Les contributions de cette thèse sont :

\begin{itemize}
  \item Une structure de contrôleur de RF est proposée pour l'interconnexion OFDMA de WiNoCoD.
  \item Plusieurs algorithmes d'allocation de bande passante efficaces (distribués et centralisés) sont proposés et leurs performances évaluées, concernant les demandes et contraintes très spécifiques de l'environnement sur-puce.
  \item Un protocole innovant pour l'arbitrage des sous-porteuses pour des longueurs bimodales de paquets sur-puce, qui ne nécessite aucune signalisation supplémentaire est introduit. 
  \item Une évaluation de l’utilisation des ordres de modulation élevés est étudiée en fonction du compromis entre délai et  consommation d'énergie.
  \item Les algorithmes proposés ne sont pas restreints aux limites de WiNoCoD, mais peuvent être étendus à d'autres interconnexions RF basées sur l'OFDMA pour les architectures CMP ou des réseaux à haute vitesse.
\end{itemize}

\section*{Chapitre 2 : L'Ere des «1000 cœurs» et le défi des réseaux-sur-puce}

\subsection*{2.1 Multiprocesseurs}

Les CMPs offrent une nouvelle réponse aux limitations des monoprocesseurs en utilisant de nombreux cœurs relativement simples plutôt qu‘un seul cœur puissant, ce qui augmente les performances à la fois en termes de puissance de calcul et d’efficacité énergétique en exploitant le parallélisme. Un cœur est une unité de traitement arithmétique qui effectue les opérations logiques et de commande, qui est généralement composé de deux entités distinctes: unité arithmétique et logique (ALU) et une unité de commande (CU).

\subsection*{2.1.1 Caches et Mémoire}
Dans un processeur multi-cœurs, chaque cœur dispose d'une mémoire pour les données et les instructions, sous la désignation Mémoire cache de niveau 1 (L1 - Level 1). La mémoire cache (antémémoire) est composée de registres temporaires pour un volume relativement faible de données, qui stocke les copies de la mémoire principale et qui offre un accès très rapide pour le cœur de traitement. En fonction de l'architecture, il peut y avoir des niveaux plus élevés de caches tels que L2 et L3. Cependant, toutes les architectures ne partagent pas cette hiérarchie. Par exemple, le CMP qui est envisagé dans ce travail de thèse a seulement un cache L1 pour chaque cœur et une mémoire RAM partagée et distribuée physiquement entre tous les coeurs, qui peut être considéré comme un cache L2. 

\subsection*{2.1.2 Protocole de Cohérence de Cache}
Les cœurs d’un multiprocesseur peuvent accéder à tout endroit dans la mémoire partagée. Cependant, quand un cœur modifie les données dans un emplacement d'adresse, il peut y avoir déjà des copies des caches simultanées dans d'autres cœurs. Par conséquent, lorsque les nouvelles données sont écrites, les cœurs (qui utilisent cette adresse) risquent d’avoir une copie erronée pour cette ligne d'adresse. Par conséquent, ces cœurs doivent être informés du changement de contenu. Ce problème d'incohérence est connu sous le terme de cohérence de cache. Il existe différents protocoles pour résoudre le problème de la cohérence de cache, mais les plus largement connus sont ``espionnage de bus" et  ``espionnage à répertoire". Dans l'espionnage, à chaque fois qu’un cœur ne peut pas retrouver les données dans son cache, il diffuse une requête de lecture sur le bus reliant tous les cœurs et les caches. Comme chaque contrôleur de cache des autres cœurs écoute ces émissions, ils invalident les copies dans leurs caches avec l'étiquette de la ligne d'adresse dans cette demande. La deuxième approche est le protocole par répertoire (directory), où les répertoires sont responsables de la mise à jour et de mémoriser les états et les propriétaires de blocs mémoire (lignes d'adresse). Chaque cœur, qui veut extraire la copie d'une adresse dans la mémoire principale, doit se référer au répertoire en premier lieu. Afin d'orchestrer l'exécution d'applications et fournir la cohérence des caches, les cœurs et les éléments de mémoire doivent communiquer entre eux. Ces messages de cohérence de cache constituent la base du profile des communications sur une telle puce. 	 	

\subsection*{2.2 Réseau-sur-Puce}
\subsection*{2.2.1 Des Bus au Réseau-sur-Puce}
Quand le nombre d'éléments reliés à un même bus augmente, la charge capacitive et résistance parasite augmentant également, ce qui est une cause supplémentaire de retard dans les transmissions sur le bus. Dans les architectures submicroniques classiques, les informations numériques sont transmises entre les noeuds par des fils de cuivre en augmentant ou en diminuant la tension électrique sur ces fils. En outre, comme le nombre d'unités qui veut accéder au bus augmente, la bande passante par unité diminue, ce qui cause d’autant plus de risques de congestion. A l'échelle des CMPs, avec un nombre de cœurs de plus en plus important, jusqu’à atteindre plusieurs milliers d’unités, un cadre de communication de manière paquetisée a été introduit, connu sous le nom de Réseau-sur-puce (NoC).

\subsection*{2.2.2 Topologies de NoC}

Depuis les recherches initiales sur les NoC, différentes topologies ont été proposées  : 2D-grille, 2D-tore, octogone etc. (Fig 0.1). Malgré ses avantages, comme nous approchons d'une ère avec des centaines, voire des milliers de cœurs, ces NoC classiques sont aux prises avec un problème d'extensibilité. Par exemple, on peut voir que la distance entre les deux cœurs les plus éloignés dans un réseau de grille est $2\sqrt{N_{cores}}$, où $N_{cores}$ est le nombre de cœurs.

\begin{figure}[htbp]
  \centering
    \includegraphics[width=0.95\textwidth, height=0.35\textwidth]{./Figures/fig01.pdf}
    \rule{35em}{0.5pt}
  \caption[Topologies NoC]{Trois des topologies les plus classiques pour les NoCs 2D, où les éléments sont interconnectés via des routeurs tamponnées: (a) grille (b) tore (c) octogone}
  \label{fig:Electron}
\end{figure}

\subsection*{2.2.3 Tera-Scale Multi-core Processor Architecture (TSAR)}
Il est important de mentionner ici le projet TSAR (Tera-Scale Multicore processeur Architecture) \cite{greiner2009tsar}. Parmi les partenaires de ce projet, l'UPMC-LIP6 et NXP Semiconductors sont aussi des partenaires du projet WiNoCoD. Dans un sens, ce projet peut être considéré comme une base primordiale de WiNoCoD, comme ses principes architecturaux en termes de mémoire et de protocole de cohérence de cache a de nombreuses caractéristiques communes avec TSAR. La différence fondamentale du projet WiNoCoD est son infrastructure NoC. En effet, TSAR a été modélisé avec un réseau de grille-2D classique pour la communication entre les tuiles (unité atomique de 4 cœurs avec sa RAM, un contrôleur de répertoire).


\subsection*{2.3 Interconnexion RF et Optiques}

Avec un horizon où des milliers de cœurs seront concentrés sur une même puce, l'industrie des semi-conducteurs a compris que les NoCs filaires classiques sont loin de fournir les besoins attendus en termes de latence, de bande passante et de contrainte de puissance électrique. Ainsi a émergé l'idée de communiquer par ondes électromagnétiques à une vitesse plus proche de celle de la lumière. L’International Technology Roadmap for Semiconductors (ITRS) affirme que les interconnexions optiques et RF représentent l’avenir pour satisfaire les besoins à long terme de bande passante, de latence, la puissance, considérant que l’on s’attend à ce que le nombre de cœurs sur une puce dépasse plusieurs milliers avant la fin de la prochaine décennie (Fig. 0.2).

\begin{figure}[htbp]
  \centering
    \includegraphics[width=0.95\textwidth]{./Figures/fig02.pdf}
    \rule{35em}{0.5pt}
  \caption[L'illustration d'options d'interconnexion]{L'illustration d'options d'interconnexion sur puce innovante récemment proposées}
  \label{fig:Electron}
\end{figure}

\subsection*{2.3.1 Interconnexions Optiques}
Les développements récents de la nanophotonique ont permis l’implantation d'éléments optiques tels que des guides d'ondes denses, des filtres, des modulateurs etc. sur une seule puce. Toutefois, ces tentatives sont encore dans la phase de début. Récemment, \cite{sun2015single} a démontré sa faisabilité dans le cas d'un simple multiprocesseur avec 2 cœurs, avec une interconnexion optique sur puce complète. Pour permettre le transfert simultané de plusieurs signaux sur le même guide d'ondes, des canaux orthogonaux (longueurs d'onde) sont générés. Une source laser sur la puce ou hors de la puce génère et fait circuler l'énergie photonique sur un guide d'onde dédié, capable de véhiculer toutes les longueurs d'onde utilisées dans le système. Des résonateurs en micro-anneaux (microring resonators) sont utilisés en tant que modulateurs pour la transmission de données et en tant que filtres pour la réception. Donc, nous pouvons comprendre que nous avons besoin d'implanter un grands nombre de ces modules pour créer tous les canaux orthogonaux nécessaires, ce qui est encombrant et consommateur d’énergie d’une part et peu évolutif d’autre part. Chacun de ces micro-anneaux est fabriqué pour une longueur d'onde spécifique, qui est déterminée par traitement thermique, et par différence de quantité de charge électrique injecté, ou en faisant varier le rayon de l’anneau au cours du processus de fabrication. Ainsi, ce système est statique par nature et il est impossible de redistribuer la bande dynamiquement entre les nœuds de traitement. ATAC et Corona sont deux exemples de l'état de l'art des architectures optiques sur puce.

Les interconnexions photoniques sont considérées comme une technologie efficace pour réduire la latence de manière significative grâce à leur grande bande passante, tout en offrant une faible consommation électrique. Cependant, leur praticabilité est mise en doute, au moins pour un avenir proche, à cause du bruit du couplage de guide d'ondes et de la taille relativement importante des composants optiques pour les intégrer en grands nombres dans une puce. La fabrication de composants photoniques sur puce est encore confrontée à de nombreux défis. Il impose la juxtaposition de deux technologies differents : la technologie CMOS pour l'architecture de traitement et la technologie optique pour l'interconnexion. En outre, il n’existe pas d'éléments de stockage optique, ainsi un tel système dépend d'une infrastructure électrique additionnelle. Comme mentionné précédemment, les NoC optiques nécessitent des sources laser constantes soit sur la puce, soit hors puce, avec un guide d'onde dédié séparé.

\subsection*{2.3.2 Interconnexions RF}

En raison des inconvénients des interconnexions optiques, les chercheurs ont orienté leurs investigations vers les interconnexions Radio Fréquence (RF), qui utilisent encore les ondes électromagnétiques (EM). La fréquence de transition des transistors CMOS est toujours dans une tendance d'augmentation exponentielle de génération en génération, permettant désormais d’envisager des fréquences maximales jusqu'à 1 THz. Cela positionne les composants RF CMOS comme des candidats naturels pour les émetteurs récepteurs sur puce à haute fréquence. L'avantage de cette approche est sa compatibilité CMOS avec la partie traitement de la puce (cœurs, mémoires, etc.). De plus, c’est une technologie beaucoup plus mature par rapport à l'optique sur puce.

Il y a deux propositions distinctes pour les interconnexions RF: par la propagation en espace libre (sans fil mais avec une antenne d’émission et une antenne de réception) ou la propagation guidée (RF filaire ou sur guide d'ondes). Pour la RF sans fil, l'idée est de générer des liaisons à haut débit entre les cœurs distants, afin de réduire la latence et la congestion, sans la nécessité d'un milieu de propagation supplémentaire dédié. Le défi majeur dans ce paradigme est la difficulté de caractériser les effets de la propagation, ainsi que la fabrication de petites antennes en nanotechnologies avec des caractéristiques électromagnétiques adéquates. La viabilité des antennes sur puce sans fil n’est pas encore démontrée et les propositions innovantes qui apparaissent, telles que les antennes en nanotubes de carbone, ne sont pas encore des technologies matures. Ainsi, la propagation RF via une ligne de transmission guidée (RF filaire) a reçu plus d'attention dans la communauté de la recherche sur puce par rapport à son homologue sans fil. Comme la distance de communication est faible, la méthode de couplage capacitif efficace peut être utilisée pour réaliser la transmission. En outre, le guide d'ondes permet une atténuation réduite, donc une puissance de transmission, qui est la plus consommatrice d’énergie dans un système de communication, limitée au plus juste (et non dispersée dans toutes les directions). C'est l'option qui sera considérée dans ce travail. 

\subsection*{2.4 Caractéristiques du Trafic sur Puce}

Comme première étape, les chercheurs se sont appuyés sur des modèles de trafic synthétiques primitifs pour évaluer leurs conceptions, mais ces modèles se révèlent souvent trop naïfs pour assurer la validité des simulations. D’autre part, il y a un nombre trop limité d'applications sur multicœurs, telles que celles fournies par PARSEC ou Splash-2. Un modèle statistique réaliste universel d’émulation du trafic d’un NoC est essentiel. Il existe différents modèles stochastiques de trafic pour la simulation sur puce dans la littérature, utilisant la notion d'auto-similarité, phénomène ayant pour origine la hiérarchie de cache dans les systèmes à mémoire partagée. Nous nous basons sur ces modèles de l'état de l'art dans notre travail.

\section*{Chapitre 3 : Projet WiNoCoD et Interconnexion RF filaire basée sur l’OFDMA}

Nous avons vu que les interconnexions RF filaires apparaissent comme le candidat le plus réaliste à court terme. Cependant, tout comme leurs homologues optiques, les interconnexions RF proposées dans l’état de l'art reposent sur des circuits analogiques pour générer des canaux fréquenciels, ce qui limite leurs capacités d'allocation dynamique des ressources, notamment en termes de coût, de surface occupée et de consommation. Pour surmonter tous ces désavantages et fournir une réelle avancée en termes de bande passante reconfigurable, le projet WiNoCoD (Wired RF Network-on-Chip Reconfigurable on Demand) a été initié en 2013, en partenariat avec l'ANR, par ETIS-ENSEA, LIP6-UPMC, Supelec-IETR et NXP Semiconductors.

\subsection*{3.1 L'architecture sur Puce de WiNoCoD}
\subsection*{3.1.1 Niveaux de Communication}

Le circuit issu de WiNoCoD est un multiprocesseur massivement parallèle et générique de 2048 cœurs de traitement. Un principe de mémoire partagée est adopté, où tout l'espace d'adresse est accessible par tous les cœurs (NUMA - Non Uniform Memory Architecture). Il existe 3 niveaux hiérarchiques principaux, avec un type d'infrastructure de communication particulier pour chaque niveau. Au niveau le plus bas se trouve la tuile, constituée de 4 cœurs, 2 Go de RAM (une sous-partie de la mémoire globale du système) et un contrôleur de mémoire. Tous ces éléments sont reliés entre eux par un crossbar switch. Au niveau suivant, 16 tuiles sont interconnectés par un réseau en quadrillage (mesh 2D). Ceux-ci sont appelés tuilesets (ou grappes de tuiles) et il y a 32 tuilesets au total. Au plus haut niveau, ces 32 tuilesets sont interconnectés par la ligne de transmission RF. Par exemple, si un cœur veut transmettre des informations à un autre cœur dans un tuileset différent, le message doit traverser les 3 différentes couches de communications. L'architecture de WiNoCoD avec 2048 cœurs est illustrée sur la Fig. 0.3.

\begin{figure}[htbp]
  \centering
    \includegraphics[width=0.90\textwidth]{./Figures/fig03.pdf}
    \rule{35em}{0.5pt}
  \caption[L'architecture à 3 niveaux de WiNoCoD, avec 2048 cœurs au total]{L'architecture à 3 niveaux de WiNoCoD, avec 2048 cœurs au total}
  \label{fig:Electron}
\end{figure}

\subsection*{3.1.2 Détails du Protocole de Cohérence de Mémoire Cache}

Nous employons dans WiNoCoD un protocole de cohérence de cache hybride par répertoire (Distributed Hybrid Cache Coherency Protocol), comme dans TSAR \cite{greiner2009tsar}. Une approche similaire est adoptée pour ATAC \cite{kurian2010atac}, qui est une architecture à 1024 cœurs interconnectés en optique. Une approche d’écriture transversale (Write Through) est adoptée, c’est-à-dire que dans le cas où un cœur veut écrire une donnée à une ligne d'adresse, il transmet une demande d'écriture dans le répertoire responsable de cette ligne d'adresse. Par conséquent, si la ligne d'adresse destinataire est associée au répertoire de la même tuile, le message ne va pas à l'extérieur de la tuile, et utilise uniquement le crossbar switch. De même, si la ligne d'adresse est dans une tuile différente mais dans le même tuileset, il utilise uniquement le réseau en quadrillage. Si la ligne d'adresse est dans une tuile d'un tuileset différente, alors il doit utiliser l'interconnexion RF. Dans le protocole DHCCP de WiNoCoD, lorsque le nombre de cœurs partagants d'une ligne d'adresse dépasse un certain seuil (par exemple 8), le répertoire commence à garder le nombre de partageurs, plutôt que de garder les identificateurs (ID) de chaque cœur explicitement. Dans ce cas, pour chaque invalidation, le répertoire diffuse un message à chacun des 2048 cœurs et compte le nombre de messages d'ACK pour vérification. C’est la seule façon d'être en mesure de suivre des milliers de partageurs possibles. Le répertoire dans une tuileset est représenté sur la Fig. 0.4.

\begin{figure}[htbp]
  \centering
    \includegraphics[width=0.70\textwidth]{./Figures/fig04.pdf}
    \rule{35em}{0.5pt}
  \caption[Contexte du répertoire de la mémoire dans une tuileset]{Context du répertoire de la mémoire dans une tuileset}
  \label{fig:Electron}
\end{figure}

\subsection*{3.2 Notions Préliminaires sur l’OFDMA}

L’OFDM (Orthogonal Frequency Division Multiplexing) est une technique de modulation qui transforme un signal de bande passante large en plusieurs canaux orthogonaux plus étroits. L’OFDM code ainsi l'information numérique sur le domaine des fréquences plutôt que dans le domaine temporel. Pour le mettre en oeuvre, les données numériques sont tout d'abord mises en symboles de constellations BPSK, QPSK, M-QAM, etc., et chaque symbole de la constellation est associé à une sous-porteuse. La sous-porteuse est l'unité de fréquence atomique dans un signal OFDM, ou en d'autres termes c’est l'ensemble de toutes les sous-porteuses à bande étroite qui sont émises en parallèle. C’est une transformée de Fourier discrète inverse (IDFT) qui est appliquée au vecteur de N symboles pour les positionner sur N sous-porteuses en parallèle, où chacun d'eux est maintenant un nombre complexe associé au symbole de la constellation codée (chaque nombre complexe représente un certain nombre de bits). Le résultat de cette transformation donne un vecteur de N nombres complexes. Après, ce vecteur de N points est sérialisé et converti en un signal dans le domaine temporel. Ce signal s'est appelé un symbole OFDM. A la réception, l'inverse de ces opérations est effectuée. Les blocs élémentaires d'un émetteur-récepteur OFDM sont montrés sur la Fig. 0.5.

\begin{figure}[htbp]
  \centering
    \includegraphics[width=0.90\textwidth]{./Figures/fig05.pdf}
    \rule{35em}{0.5pt}
  \caption[Les blocs de base d'un émetteur-récepteur OFDM]{Les blocs de base d'un émetteur-récepteur OFDM}
  \label{fig:Electron}
\end{figure}

Les avantages de l'OFDM peuvent être énumérés comme suit :

\begin{itemize}
  \item Robustesse contre les canaux sélectifs en fréquence et l'égalisation est simple pour chaque sous-porteuse.
  \item Génération de canaux fréquentiels par un processus numérique, d'où l’économie de nombreux circuits analogiques.
  \item Une bande passante reconfigurable grâce à une mise en œuvre numérique.
  \item Haute efficacité spectrale grâce à des sous-porteuses fenêtrées par des fonctions sinc orthogonales.
\end{itemize}

L’OFDMA (Orthogonal Frequency Division Multiple Access), d'autre part est un schéma d'accès multiple basé sur l’OFDM, avec tous les avantages de la couche physique de l'OFDM dont une bande passante reconfigurable par utilisateur. Un utilisateur encode l'information sur ses sous-porteuses allouées à la transmission comme expliqué précédemment, et maintient les autres inactives (zéro avant IFFT) pour les laisser libres à d'autres utilisateurs. Cette procédure est mise en oeuvre dans le domaine numérique, simplement en manipulant le vecteur de bits avant l'IFFT. Cette tâche peut être réalisée par un microprocesseur ou un circuit numérique. En outre, comme chaque noeud dans le système doit décoder un symbole OFDM en entier pour extirper le signal le concernant, l’OFDMA est doté de capacités de diffusion intrinsèques.

\subsection*{3.3 L'Interconnexion RF guidée de WiNoCoD basée sur l’OFDMA}

La technologie des convertisseurs fournis par notre partenaire NXP a une bande passante de 20 GHz. En raison des contraintes d’adaptation et de la propagation guidée, le spectre le plus approprié a été choisi entre 20-40 GHz. Il est décidé d’avoir 1024 sous-porteuses OFDM, ainsi des modules FFT et IFFT de 1024 points sont nécessaires. Comme nous avons la bande passante est de 20 GHz, avec 1024 sous-porteuses l’espacement de fréquence entre les sous-porteuses est de 19.53 MHz, soit une durée symbole de T = 1 / 19.53 MHz = 51.2 nanosecondes.  

\subsection*{3.3.1 Contrôleur RF}

Un paquet qui doit être envoyé par une tuile dans la ligne guidée RF est routé à travers le réseau en quadrillage du tuilset vers le contrôleur RF de ce tuileset. Ces paquets sont traités si nécessaire, c’est-à-dire fragmentation ou défragmentation, extraction ou insertion d’informations telles que l’identifiant de la source, etc., puis insérés dans la file d'attente de transmission. Le contrôleur RF prend certaines décisions selon des informations qu’il possède de l'état de sa file d'attente (Queue State Information - QSI) de transmission (TX) et les informations de trafic en provenance d'autres tuilesets qu’il peut recevoir directement des autres tuilesets, soit lui être fournis par une unité centrale intelligente (Central Intelligent Unit-CIU). Le contrôleur RF modifie en fonction la position et l’encodage en symboles des données dans son buffer précédent la IFFT et configure ainsi son occupation des sous-porteuses du symbole OFDM qui va être transmis. Chaque tuileset fait de même pour chaque symbole OFDM et les porteuses d’un symbole OFDM sont ainsi réparties entre tous les tuilesets. La répartition de l’occupation des sous-porteuses entre les tuilsets est l’enjeu de la thèse et plusieurs algorithmes vont être proposés dans le manuscrit. L’un ou l’autre pourra être utilisé en changeant le programme du ou des processeurs du contrôleur RF gérant le buffer d’émission.

\subsection*{3.3.2 Tête analogique RF}

Cette partie est le travail de thèse de Frédéric Drillet et Lounis Zerioul du laboratoire ETIS. Dans la tête d’émission analogique RF, les mélangeurs associent un signal OFDM en bande de base avec la porteuse issue de l'oscillateur local. Le mélange se produit dans un MOSFET, dont la grille et le drain sont respectivement alimentés par l'oscillateur local et le signal en bande de base. La sortie de fréquence plus élevée est récupérée dans la source de transistor MOSFET. Grâce aux sorties différentielles du convertisseur numérique-analogique (CNA), deux modulateurs-I/Q sont combinés pour supprimer les replicas de fréquences. Ensuite, ce signal est amplifié par un amplificateur et injecté sur la ligne RF par un couplage à transistors qui a été préféré à un couplage capacitif classique. 

En réception, le signal reçu de la ligne de transmission est amplifié par un amplificateur à faible bruit (LNA) et envoyé aux mélangeurs et l'oscillateur local de 30 GHz pour obtenir les composantes en phase (I) et en quadrature (Q). Des filtres passe-bas (LPF) sont également utilisés puis les composantes I et Q sont converties dans le domaine numérique par les convertisseurs analogique-numérique (CAN). Apres une conversion série vers parallèle, ce vecteur de valeurs I et Q est transposé dans le domaine fréquenciel par un module de transformée de Fourier rapide (FFT). Les symboles de la constellation qui en résultent sont extraits sous forme de bits; sérialisés et finalement sont fournies au contrôleur RF en réception. La tête d’émission et de réception analogique d’un tuileset est illustrée sur la Fig. 0.6. 

\begin{figure}[htbp]
  \centering
    \includegraphics[width=0.99\textwidth]{./Figures/fig06.pdf}
    \rule{35em}{0.5pt}
  \caption[La tête numérique et la tête analogique RF pour la transmission et la réception dans un tuileset]{La tête numérique et la tête analogique RF pour la transmission et la réception dans un tuileset}
  \label{fig:Electron}
\end{figure}

Les modules FFT et IFFT sont conçus en technologie CMOS 120 nm. Il a été estimé que la superficie de chacun de ces modules est de 0,31 mm2 et la consommation d'énergie de 67.5 mW. La durée de calcul pour FFT / IFFT est considérée comme une latence du pipeline de la communication. Chacun des CAN et CNA sont conçus avec la technologie 120 nm et ont une superficie estimée de 0,12 mm² et leur consommation d'énergie de 81 mW. 

L’étude de la ligne de transmission s’est effectuée dans le cadre de la thèse de Mohamad HAMIEH du laboratoire ETIS. Une ligne de transmission en forme de croix, comme illustré sur la Fig. 0.3 a été conçue pour minimiser la distance entre les deux tuilesets plus éloignés du CMP. Dans cette configuration, la distance maximale entre deux noeuds est de 80 mm. La forme en croix donne également un avantage supplémentaire, en fournissant une réponse en fréquence plate sur la bande passante de 20 GHz. Sur la gamme de fonctionnement, entre 20 et 40 GHz, l'atténuation attendue (issue des simulations) est de -10 dB à -42 dB entre les deux nœuds les plus éloignés et relativement linéaire sur toute la gamme de fréquence. Ceci peut paraitre variable mais comparativement au cas aérien qui connait beaucoup de variations fréquentielles et temporelles, on peut faire l'approximation ici de une certaine stabilité. On retrouve cette quasi-invariabilité en fréquence entre tous les autres noeuds, avec des atténuations plus faibles au fur et à mesure que la distance décroît entre les deux nœuds considérés. Cela simplifie l'utilisation de l’OFDM puisque toutes les sous-porteuses subiront la même atténuation quelle que soit la fréquence utilisée dans le système. Seule la position relative entre les nœuds fera varier l’atténuation qui donc sera prévisible.  Le choix des porteuses ne nécessitera pas ainsi de modifier la puissance de transmission, mais seulement le choix de l’ordre de modulation. Une ligne coplanaire en technologie CMOS à 0.25 micromètre fournie par NXP semiconductor est utilisée. Un mécanisme d'accès par transistor est préféré la celui d'un couplage capacitif classique pour accéder à la ligne de transmission depuis les têtes analogiques d’émission et de réception  des tuilesets. Le signal est transmis entre la ligne guidée de transmission et la tête RF sans contact physique. Cette méthode réduit le phénomène des réflexions  et de l'atténuation fluctuante sur différentes fréquences (désadaptation). 


\section*{Chapitre 4 : Problème d'allocation de la bande passante d’un RF NoC}

\subsection*{4.1 Interconnection OFDMA de WiNoCoD et motivation}

Nous avons vu que chaque tuileset a un point d'accès à la ligne de transmission via un modulateur/démodulateur OFDMA. Grâce à la capacité de diffusion intrinsèque de l’OFDMA, chaque paquet envoyé n'a pas besoin d'être dupliqué pour être diffusé, comme toutes les transmissions effectuées par un utilisateur sont reçues par tous les autres (SWMR). Ceci augmente considérablement la capacité du système compte tenu de l'exigence particulière, dans le cas d'un système à cohérence de cache de répertoire, en termes de nombre de paquets de diffusion / multidiffusion. Une sous-porteuse sur un symbole OFDM peut être considérée comme un élément servant à la transmission de l'information (1,2, etc. bits sur la base de l'ordre de modulation utilisé BPSK, QPSK, etc.). Comme mentionné précédemment, la motivation principale derrière l'utilisation de l’OFDMA sur puce est sa capacité de reconfiguration, qui se réfère à la facilité de changer les utilisateurs de sous-porteuses, ou le nombre de porteuses par utilisateur, au cours du temps. Par conséquent, notre problème peut être formulé sous la forme de l'attribution des sous-porteuses au cours du temps (par exemple sur une durée de un ou plusieurs symboles OFDM) aux différentes files d'attente de transmission des tuilesets. Dans l'hypothèse où les files d'attente de réception en sortie de la ligne de transmission peuvent être vidées avec une rapidité élevée, en tout état de cause supérieure à celle d’arrivée des paquets, nous pouvons affirmer que l'allocation dynamique de sous-porteuses devrait diminuer les latences dans les files d'attente du côté de la transmission. Il est à noter que cette hypothèse est très légère, puisque cela signifie que les paquets reçus en sortie de la ligne de transmission peuvent être transmis dans le réseau intra-grille d’un tuileset à haute vitesse, ce qui est le cas car le réseau en quadrillage est un réseau parallèle sur 32 ou 64 bits fonctionnant habituellement à plusieurs centaines de mégahertz de fréquence d’horloge. Il peut donc drainer 64 bits toutes les nanosecondes à 1 GHZ d’horloge, soit bien plus que des données sur 64 bits (ou un multiple de 64 bits inférieur à 10) arrivant de la ligne de transmission toutes les 51.2 ns. Par conséquent, dans ce projet, nous cherchons des mécanismes d'arbitrage de l’allocation des sous-porteuses afin de minimiser le retard dans les files d'attente de transmission des tuilesest, en entrée de la ligne de transmission, et les probabilités de dépassement de capacité des mémoires tampons ou files d’attente de l’émetteur des tuilesets vers la ligne de transmission. Les détails de la spécification des protocoles proposés dans le cadre de cette thèse, tels que la structure détaillée des bits d’un paquet, etc., ne sont pas compris dans ce travail de thèse. Un processus générique de mécanisme d'allocation de la bande passante est prévu, qui peut être utilisé pour tout type d'architecture massivement multicoeurs, au-delà du cas de WiNoCoD.

\subsection*{4.2 Ordonnancement dynamique de la bande passante pour les files d'attente parallèles}

La problème présenté précédemment est référencé dans la littérature comme ``l'ordonnancement multi-utilisateur multi-serveur" ou ``l'ordonnancement des files d'attente parallèles". La recherche sur les politiques d'ordonnancement multi-utilisateurs pour le cas multi-serveurs intègre les domaines de la théorie des files d'attente, la théorie des réseaux, l’optimisation stochastique et les processus de décision markoviens. Considérant la nature de notre interconnexion OFDMA, nous allons étudier les algorithmes les plus efficaces en termes de politiques dynamiques d'ordonnancement. Ce type d’approches réassignent habituellement les serveurs aux files d'attente à chaque (ou chaque multiple) intervalle de temps, basé sur l'état instantané du système.

Pour le cas où il ya un seul serveur, qui doit être attribué à l'une des K files d'attente à chaque intervalle de temps (multi-utilisateur/serveur unique), il a été prouvé que la politique d’allocation prioritaire à la plus longue file d'attente (Longest Queue First: LQF) fournit la plus faible latence moyenne, sachant que les arrivées des paquets aux files d'attente sont indépendantes et identiquement distribuées. L'optimalité de cet algorithme pour le cas de plusieurs serveurs est toujours valable sous l'hypothèse d'arrivées indépendantes. L'inconvénient de cet algorithme est sa complexité de calcul. Il procède par itérations sur les N serveurs, et à chaque itération, le serveur effectue une itération pour toutes les files d'attente K. Après l'affectation, les longueurs des files d'attente sont mises à jour. Même si sa mise en œuvre dans WiNoCoD est impossible, en raison de la puissance de calcul requise excessive et, plus important en raison du fait que l'algorithme a besoin de connaître le temps d'attente instantanée de chaque paquet dans le système, nous utilisons cet algorithme comme référence pour comparer les performances de nos politiques d'allocation de bande passante. 

\subsection*{4.3 Allocation de la bande passante dans WiNoCoD}

L’innovation de l'interconnexion RF de type OFDMA de WiNoCoD nécessite de développer de nouvelles techniques. La durée relativement longue des symboles OFDM à l'égard de temps d'arrivée des paquets dans les files d’attente d’émission des tuilesets, les longueurs des paquets et les exigences en termes de retard extrêmement strictes rendent cet environnement vraiment unique par rapport aux protocoles de communication existants, basés sur l’OFDMA. Par conséquent, dans cette section, nous introduisons certaines notions préliminaires liées à ce contexte particulier, et qui auront un impact sur l'allocation de la bande passante dans WiNoCoD.

\subsubsection*{4.3.1 Bloc de ressources et trames}

La première notion que nous présentons est le bloc de ressources (Resource Block: RB), qui définit un groupe de sous-porteuses adjacentes sur un seul symbole. Considérant que nous avons 1024 sous-porteuses, il est évident qu’une granularité très fine pour allouer la bande passante avec une seule ou quelques sous-porteuses est coûteuse et inutile. Elle est notamment coûteuse en termes d’adressage et nécessitera l’échange de nombreux bits d’adresse pour informer les contrôleurs RF des tuilesets de leur allocation respective. Nous avons choisi de définir un RB pour servir exactement 1 paquet court (1 flit - 64 bits), en supposant que la modulation QPSK est utilisée par défaut. Un RB correspond donc à 32 sous-porteuses. Il est aussi à noter que comme le projet WiNoCoD prévoit l’utilisation de 1024 porteuses et 32 tuilesets, il y a en moyenne un RB de 32 porteuses disponible par tuileset. C’est une configuration qui pourra être utilisée par défaut, au lancement notamment, avec un RB d’émission pour chaque tuileset. 

Le spectre de 20 GHz est donc divisé en RBs de 32 porteuses soit 625 MHz. Etudions maintenant les politiques de répartition des RB entre les tuilesets et le processus de reconfiguration associé. Comme nous l'avons examiné précédemment, les algorithmes efficaces d'allocation de bande passante nécessitent d'utiliser l'information de longueur des files d'attente (QSI). En outre, il est nécessaire que cette information soit récente, afin d'atteindre de faibles délais de livraison des paquets et de faibles tailles de files d‘attente au niveau de l’émetteur d’accès à la ligne de transmission, géré par le contrôleur RF de chaque tuileset. Cependant, l’échange de l’information de QSI entre les tuileset à chaque symbole n’est pas réaliste en raison des besoins de signalisation excessive qu’il provoquerait d’une part. D’autre part, des paquets peuvent arriver à la file d’attente d’émission pendant la durée d’un symbole OFDM de 51,2 ns. L’information de QSI n’est donc par définition jamais complètement à jour quand elle est envoyée. Nous envisageons un système, où les QSIs (ou d'autres indicateurs de trafic local, en tenant compte d'autres algorithmes possibles) sont diffusés par les tuilesets tous les T symboles et la nouvelle répartition des sous-porteuses est effectuée tous les T symboles. Grâce à la capacité de diffusion de l'interconnexion OFDMA, les QSIs qui sont envoyés par chaque tuileset peuvent être reçus par tous les autres. Nous appelons «trame» ce groupe de T symboles. Ainsi, à la fin, nous avons un système d'allocation en mode pipeline, c’est-à-dire décalé d’une trame au moins. L'allocation est calculée au début d'une trame selon des informations de QSI envoyées T symboles avant par les autres tuilsets, comme le montre la Fig. 0.7.

Dans le cas spécifique de WiNoCoD, où 1 symbole est d’environ 50 ns, le temps de calcul apparaît comme un paramètre important. Cette exigence temporelle stricte et peu orthodoxe fait de ce problème d'attribution, qui est examiné dans cette thèse, un travail original par rapport aux systèmes classiques. En effet, il n’est pas possible d'amortir sur une durée inférieure à celle d’un symbole, non seulement le temps des calculs d’un algorithme d’allocation, mais aussi le retard cumulé du temps de reconfiguration des sous-porteuses, du traitement des paquets, la synchronisation, le temps de propagation etc. D’où la nécessité de gérer le problème en trames de T symboles.


\begin{figure}[htbp]
  \centering
    \includegraphics[width=0.80\textwidth]{./Figures/fig07.pdf}
    \rule{35em}{0.5pt}
  \caption[Les trames et blocs de ressources (RBs) dans WiNoCoD]{Les trames et blocs de ressources (RBs) dans WiNoCoD}
  \label{fig:Electron}
\end{figure}

\subsubsection*{4.3.2 Allocation décentralisée et centralisée}

Les mécanismes d'arbitrage d’allocation des sous-porteuses que nous avons développé pour l'interconnexion WiNoCoD, peuvent être divisés en deux catégories : décentralisés et centralisés. Chacune des approches a des avantages et des inconvénients. Si une allocation centralisée est préférée, une seule unité centrale intelligente (Central Intelligent Unit: CIU), qui peut être soit un circuit numérique soit un microprocesseur simple, peut être installé à l'intérieur de la tête RF d'un tuileset (avant les modules IFFT/FFT). De cette façon, il peut utiliser les modulateur/démodulateur OFDM de ce tuileset. L'unité centrale intelligente doit diffuser sur la ligne guidée le nombre de RBs alloués à chaque tuileset. Ceci est une surcharge de signalisation supplémentaire évidente, ce qui n'est pas souhaitable afin d’épargner au maximum la bande passante sur la ligne guidée pour les échanges de données entre tuilesets. 

Un autre inconvénient est la robustesse. D’une part si le CIU connaît une panne, toute la puce est en panne. Mais l’approche proposée ici peut permettre de choisir n’importe quel tuileset pour héberger le CIU, ce qui atténue légèrement cet effet (l’étude de capacité du dernier chapitre tempèrera cette affirmation en révélant qu’il faut mieux que le CIU soit au centre la la ligne guidée). D’autre part, nous avons positionné la réponse du CIU sur des sous-porteuses réservées sur quelques symboles avant la fin de la trame. Nous nous réservons $T_{configuration}$ symboles de temps pour que les processeurs de la tête RF des tuilesets puissent recevoir et démoduler le nombre de RBs alloués à chaque tuileset dans la trame suivante et reconfigurer leurs transmissions en conséquence. Nous proposons deux approches différentes pour l'attribution des RBs de chaque trame entre les tuilesets: l'allocation «en fréquence» ou «en temps».

Cependant, par moments, la somme des demandes de RB de tuilesets peut être beaucoup plus faible que le nombre total de RBs dans une trame. Dans ces cas là, il peut exister des RBs inutilisés. Considérant que des nouveaux paquets peuvent arriver dans les files d’attente d’émission des tuilesets pendant ces symboles inactifs, on répartit les RBs vides uniformément entre les tuilesets, ce qui permet à un tuileset d'utiliser un RB par symbole pour tout paquet qui arriverait pendant une trame. La nature numérique de la répartition des RBs en OFDMA rend ce processus trivial.

\subsubsection*{4.3.3 Encodage et signalisation des QSIs}

Un autre aspect important est l'encodage des QSIs des tuilesets au début d'une trame. En cas de constellation QPSK, nous avons 2048 bits disponibles dans chaque symbole OFDM. Sur la base de nos simulations, l’utilisation de 8 bits par tuileset et par trame pour coder les QSI s’est révélé offrir le meilleur compromis en termes de performance globale. Avec 8 bits, il est possible de coder 256 niveaux différents. Bien sûr, la file d'attente vide (0 QSI) doit aussi être codée. En regardant les résultats de simulation, nous avons vu que le nombre de flits dans une file d'attente de transmission dépasse très rarement 255 dans les scénarios évalués. Par conséquent, toutes les valeurs de longueur de QSI entre 0 et 255 sont directement codées, et si le nombre de flits est supérieur à 255, il est codé par 255. Bien sûr, on peut choisir différentes approches et granularité de codage des QSI. Chaque valeur de QSI pourrait aussi représenter plusieurs flits. Il y a un compromis évident entre une surcharge de signalisation de QSI et la précision de l'algorithme d'allocation. Cependant, à partir de nombreuses possibilités, et en prenant en compte des configurations d'interconnexion réalistes, nos simulations ont révélé que l'encodage sur 8-bits proposé semble viable et efficace.

Les contraintes très spécifiques des interconnexions sur puce en OFDMA imposent de respecter certaines exigences. Compte tenu de la durée relativement longue des symboles par rapport aux exigences de retard sur les paquets, même une latence de quelques  symboles est importante, contrairement aux cas classiques d’utilisation de l’OFDM. Dans ce contexte particulier, la dynamique de la file d'attente peut changer radicalement en quelques symboles. Comme expliqué ci-dessus, en raison des contraintes de temps de calcul et de surcharge de signalisation, la répartition est effectuée en «pipeline» entre trames. En d'autres termes, la répartition se fait avec sur des QSI ayant T symboles de retard. Compte tenu du trafic temporellement très hétérogène, nous introduisons la notion de ``QSI Définitif" (Definitive QSI - DQSI). Au début de chaque trame, avant de coder son QSI sur les sous-porteuses réservées, chaque tuileset connaît déjà le nombre de RBs attribué dans la trame actuelle. Par conséquent, plutôt que de coder directement le QSI, il soustrait le nombre de RBs déjà alloué de son QSI courant.
Une fois que le nombre minimum de flits dans la file d'attente est déterminé, nous pouvons également prendre en compte le nombre de flits qui arriveront au cours du processus d'allocation (sur la durée de la trame actuelle). Pour ce faire, les tuilesets doivent estimer le nombre de flits qui arriveront pendant une trame. Cela peut se faire en utilisant un filtre à moyenne mobile. Nous appelons ce modèle comme ``QSI prédit" (\textit{Expected Queue State Information - EQSI}).

Avant de présenter nos algorithmes, il est essentiel d'introduire les techniques et les scénarios que nous allons utiliser pour les évaluer. Nous utilisons OMNeT++, un simulateur d'événements discrets qui est utilisé largement auprès la communauté réseau sur puce. OMNeT++ est utilisé pour émuler la dynamique des files d'attente de transmission des 32 tuilesets. Les simulations sont exécutées avec un pas temporel égal à celui d’un symbole OFDM, qui est donc l'unité atomique temporelle. L’objectif est l'amélioration des performances de l’interconnexion RF en termes de latence de délivrance des paquets présents dans les files d’attente d’émission des tuilest. la première métrique d'intérêt que nous essayons d'améliorer est la latence moyenne. La latence moyenne d’un réseau sur puce, pour différents modèles de trafic et des charges de trafic différentes, est la mesure la plus significative de sa performance. L'importance du retard des paquets dans un NoC est particulièrement sensible pour les applications temps réel. Par conséquent, notre interconnexion RF est testée en premier pour cette métrique. En outre, pour chaque simulation; nous traçons la courbe de la probabilité de dépassement de limite de latence, qui indique la probabilité qu'un paquet dépasse une limite de latence spécifiée, $D_{0} : P (D> D_{0})$. La troisième métrique d'intérêt, est la courbe de probabilité de dépassement de la limite de longueur de queue : $P (L> L_{0})$.

Cependant, pour tester les performances du NoC, les benchmarks de référence actuels en termes de génération de trafic sur la ligne guidée sont loin de représenter la charge générée par les futurs algorithmes qui seront embarqués sur des architectures de plusiuers milliers de cœurs de traitement. Par conséquent, pour évaluer la validité de notre interconnexion OFDMA et des algorithmes d'arbitrage des ressources fréquentielles proposés, nous avons choisi d'utiliser des modèles de trafic stochastiques et synthétiques.

\section*{Chapitre 5 : Algorithmes d'Allocation de bande passante de WiNoCoD}

\subsection*{5.1 Allocation Série avec QSI Directe}

Le première algorithme que nous proposons est relativement simple à mettre en œuvre. Après que les valeurs des QSIs soient diffusées dans la ligne guidée, puis acquises par chaque tuileset, le contrôleur RF de ces derniers alloue simplement les RBs en série dans la prochaine trame (matrice de RBs), en itérant sur les valeurs de QSI issues de chaque tuilesets (puisque chaque tuileset peut décoder toutes les valeurs émises par tous les autres tuilesets). L'algorithme se termine lorsqu'il n'y a plus de RBs vides ou si toutes les demandes des tuilesets sont servies. Pour le cas où le QSI total de tous les tuilesets est inférieur au nombre total de RBs dans la trame, les RBs restants sont partagés entre les tuilesets en utilisant la matrice d'allocation par défaut. On peut se demander si l'allocation des RBs peut également être faite unité par unité, en itérant sur chaque tuilesets pour chaque RB à allouer ou avec une approche complètement différente. Cependant, limiter le nombre d'itérations est essentiel. Considérant que le budget temporel est de quelques centaines de cycles de processeur pour le calcul de l'arbitrage de la bande passante entre les tuilesets, itérer sur 32 tuilesets n’est réalisable qu’une seule fois. 

Comme l’algorithme d'allocation de QSI en série est de faible complexité (de calcul), on peut le dupliquer dans chaque tuileset pour un surcoût négligeable et on s’affranchit des problèmes déjà évoqués, inhérents à l’utilisation d’une unité centralisée. Cependant, nous effectuons la même expérimentation que pour le cas décentralisé, pour des raisons de cohérence. Tout au long de cette thèse, quand nous comparons l’approche centralisée à l'approche décentralisée, nous utilisons toujours un temps de reconfiguration $T_{configuration} = 2$ symboles. Par exemple, lorsque l'on compare une longueur de trame décentralisée de 4 symboles (principalement en raison du temps de calcul), nous utilisons une longueur de trame de 6 symboles pour l'approche centralisée. Rappelons que, dans l'approche centralisée, nous avons des RBs réservés pour la transmission des paquets de réponse.

Par exemple, les Fig. 0.8 et Fig. 0.9 montrent les variations de la latence moyenne en fonction du taux d'injection dans le cas d’un trafic réaliste non-uniforme (DPBPP) pour l'allocation série, avec l'approche centralisée et décentralisée, pour différentes longueurs de trame. 

\begin{figure}[htbp]
  \centering
    \includegraphics[width=0.7\textwidth]{./Figures/serial_decentral_plain_DPBPP_copy.eps}
    \rule{35em}{0.5pt}
  \caption[Latence moyenne en fonction de l'augmentation du taux d'injection pour un trafic réaliste non-uniforme (DPBPP) pour l'allocation serie avec l'approche décentralisée pour différentes longueurs de trame.]{Latence moyenne en fonction de l'augmentation du taux d'injection pour un trafic réaliste non-uniforme (DPBPP) pour l'allocation serie avec l'approche décentralisée pour différentes longueurs de trame.}
  \label{fig:Electron}
\end{figure}

\begin{figure}[htbp]
  \centering
    \includegraphics[width=0.7\textwidth]{./Figures/serial_central_plain_DPBPP_copy.eps}
    \rule{35em}{0.5pt}
  \caption[Latence moyenne avec l'augmentation du taux d'injection sous le trafic réaliste non-uniforme (DPBPP) pour l'allocation serielle avec l'approche centralisée pour différentes longueurs de trame.]{Latence moyenne en fonction de l'augmentation du taux d'injection sous le trafic réaliste non-uniforme (DPBPP) pour l'allocation serie avec l'approche centralisée pour différentes longueurs de trame.}
  \label{fig:Electron}
\end{figure}

\subsubsection*{5.1.1 Allocation Série à Deux Itérations}

L'algorithme serie ne permet pas d’approcher de près les performances idéales en termes de capacité du réseau. Une allocation de bande passante très fréquente, donc avec des longueurs de trames très courtes, provoque une augmentation significative de la latence moyenne. Nous avons observé que cet effet contradictoire est dû au faible nombre de RBs à allouer pour des longueurs de trames courtes. En utilisant la même priorité pour tous les tuilesets, certains vont prendre les RBs, et vont priver de ressources d’autres tuilesets qui en auraient besoin. Afin de résoudre ce problème d'équité, et d'augmenter l'équité entre les files d'attente de transmission des tuilesets, nous avons établi une modification de l'algorithme série. Cette fois, la répartition des RBs est effectuée en 2 étapes, comme le nom de l’algorithme l'indique. Tout d'abord après avoir reçu les QSIs de chaque tuileset, les contrôleurs RF des tuilesets les additionnent et divisent le résultat obtenu par le nombre de tuilesets afin d’obtenir le ``QSI moyen" de la trame courante. A la première étape de l'algorithme, une itération sur les 32 tuilesets est effectuée comme dans l'allocation série précédente. Toutefois, lors de cette première itération, seulement les tuilesets qui ont un QSI plus grand que le ``QSI moyen" courant peuvent prendre des RBs. Après cette première itération, les valeurs de QSI sont mises à jour en soustrayant le nombre de RBs déjà alloués à cette itération. À la deuxième étape, la même itération est effectuée sur les valeurs mises à jour de QSI des tuilesets, mais cette fois avec l'algorithme d'allocation série par défaut. De cette manière, nous nous assurons que les tuilesets qui ont vraiment besoin de RB vont obtenir leur part. Cette extension de l’algorithme d'allocation de QSI série directe peut être considérée comme une tentative pour compenser les déséquilibres dans les files d'attente.

Les Fig. 0.10 et Fig. 0.11 montrent la variation de la latence moyenne en fonction du taux d'injection sous le trafic réaliste non-uniforme (DPBPP) pour l'allocation série avec deux itérations, dans le cas de l'approche centralisée et décentralisée, pour différentes longueurs de trame. 

\begin{figure}[htbp]
  \centering
    \includegraphics[width=0.7\textwidth]{./Figures/serial_decentral_2loop_DPBPP_copy.eps}
    \rule{35em}{0.5pt}
  \caption[Latence moyenne en fonction de l'augmentation du taux d'injection pour un trafic réaliste non-uniforme (DPBPP) pour l'allocation serie (2 iterations) avec l'approche décentralisée pour différentes longueurs de trame.]{Latence moyenne en fonction de l'augmentation du taux d'injection pour un trafic réaliste non-uniforme (DPBPP) pour l'allocation serie (2 iterations) avec l'approche décentralisée pour différentes longueurs de trame.}
  \label{fig:Electron}
\end{figure}

\begin{figure}[htbp]
  \centering
    \includegraphics[width=0.7\textwidth]{./Figures/serial_central_2loop_DPBPP_copy.eps}
    \rule{35em}{0.5pt}
  \caption[Latence moyenne avec l'augmentation du taux d'injection pour un trafic réaliste non-uniforme (DPBPP) pour l'allocation serie (2 iterations) avec l'approche centralisée pour différentes longueurs de trame.]{Latence moyenne en fonction de l'augmentation du taux d'injection pour un trafic réaliste non-uniforme (DPBPP) pour l'allocation serie (2 iterations) avec l'approche centralisée pour différentes longueurs de trame.}
  \label{fig:Electron}
\end{figure}

\subsubsection*{5.1.2 Allocation Série avec DQSI et EQSI}

Nous avons vu qu’il était possible d'augmenter la capacité du réseau en utilisant une modification de l’algorithme série, en le passant à deux iterations. Dans l'approche décentralisée, chaque tuileset calcule sa propre valeur de DQSI ou EQSI en utilisant le nombre de RBs actuellement alloués et/ou instantanés. Ensuite, cette valeur est diffusée sur le premier symbole de la trame suivante. Mais dans l'approche centralisée, seuls les tuilesets diffusent leurs valeurs de QSI instantanés et c’est le CIU qui est responsable du calcul du DQSI/EQSI de chaque tuileset. 

Les Fig. 0.12 et Fig. 0.13 montrent la variation de la latence moyenne en fonction du taux d'injection dans le cas d’un trafic réaliste non-uniforme (DPBPP) pour l'allocation série avec l’algorithme DQSI/EQSI, pourl'approche centralisée et décentralisée, et pour différentes longueurs de trame. 



\begin{figure}[htbp]
  \centering
    \includegraphics[width=0.7\textwidth]{./Figures/serial_decentral_DQSI_EQSI_DPBPP_copy.eps}
    \rule{35em}{0.5pt}
  \caption[Latence moyenne en fonction de l'augmentation du taux d'injection pour un trafic réaliste non-uniforme (DPBPP) pour l'allocation serie(DQSI/EQSI) avec l'approche décentralisée pour différentes longueurs de trame.]{Latence moyenne en fonction de l'augmentation du taux d'injection pour un trafic réaliste non-uniforme (DPBPP) pour l'allocation serie (DQSI/EQSI) avec l'approche décentralisée pour différentes longueurs de trame.}
  \label{fig:Electron}
\end{figure}

\begin{figure}[htbp]
  \centering
    \includegraphics[width=0.7\textwidth]{./Figures/serial_central_DQSI_EQSI_DPBPP_copy.eps}
    \rule{35em}{0.5pt}
  \caption[Latence moyenne en fonction de l'augmentation du taux d'injection pour un trafic réaliste non-uniforme (DPBPP) pour l'allocation serie (DQSI/EQSI) avec l'approche centralisée pour différentes longueurs de trame.]{Latence moyenne en fonction de l'augmentation du taux d'injection pour un trafic réaliste non-uniforme (DPBPP) pour l'allocation serie (DQSI/EQSI) avec l'approche centralisée pour différentes longueurs de trame.}
  \label{fig:Electron}
\end{figure}

En comparant ces résultats de l'allocation série simple et directe à ceux de l’allocation en deux itérations, le résultat le plus remarquable est de constater la diminution substantielle de la latence moyenne, simplement en utilisant DQSI. Il n’élimine pas seulement l'allocation de ressources inutiles, mais il compense également l'iniquité en raison du petit nombre de RBs. 

\subsection*{5.2 Allocation QPS}

\subsection*{5.2.1 Allocation proportionelle aux longueurs des files d'attente  }

Dans la section précédente, nous avons proposé et examiné la faisabilité de probablement l’option la plus simple, sous la forme de l’algorithme série avec QSI directe, où les tuilesets diffusent leur QSI et les RBs sont arbitrés séquentiellement en une seule (ou deux) itération pour la prochaine trame. La principale motivation derrière cette pratique est d'être en mesure d'effectuer l'opération d'allocation en quelques centaines de nanosecondes, car s’y ajouteront tous les autres retards cumulatifs supplémentaires découlant de la propagation, la synchronisation, la transformation, etc.. C’est une contrainte stricte imposée, par les particularités de l'interconnexion OFDMA et de l'environnement sur puce quand une bande passante de 20 GHz ou plus est utilisée (ce qui diminue la durée des symboles OFDM à nombre de porteuses constant).

Dans cette section, nous évaluons la viabilité, dans notre contexte, de l'ordonnancement proportionnel aux longueurs des files d'attente (\textit{Queue Proportional Scheduling-QPS}). Il ajoute une complexité supplémentaire limitée par rapport à l'allocation série. L’idée est d'allouer les RBs dans les trames de manière proportionnelle à la valeur des QSIs des tuilesets. 

Les Fig. 0.14 et Fig. 0.15 montrent les variations de la latence moyenne en fonction du taux d'injection dans le cas d’un trafic réaliste non-uniforme (DPBPP) pour l'allocation QPS, pour l'approche centralisée et décentralisée, et pour différentes longueurs de trame. 


\begin{figure}[htbp]
  \centering
    \includegraphics[width=0.7\textwidth]{./Figures/QPS_decentral_plain_DPBPP_copy.eps}
    \rule{35em}{0.5pt}
  \caption[Latence moyenne en fonction de l'augmentation du taux d'injection pour un trafic réaliste non-uniforme (DPBPP) pour l'allocation QPS avec l'approche décentralisée pour différentes longueurs de trame.]{Latence moyenne en fonction de l'augmentation du taux d'injection pour un trafic réaliste non-uniforme (DPBPP) pour l'allocation QPS avec l'approche décentralisée pour différentes longueurs de trame.}
  \label{fig:Electron}
\end{figure}

\begin{figure}[htbp]
  \centering
    \includegraphics[width=0.7\textwidth]{./Figures/QPS_central_plain_DPBPP_copy.eps}
    \rule{35em}{0.5pt}
  \caption[Latence moyenne en fonction de l'augmentation du taux d'injection pour un trafic réaliste non-uniforme (DPBPP) pour l'allocation QPS avec l'approche centralisée pour différentes longueurs de trame.]{Latence moyenne en fonction de l'augmentation du taux d'injection pour un trafic réaliste non-uniforme (DPBPP) pour l'allocation QPS avec l'approche centralisée pour différentes longueurs de trame.}
  \label{fig:Electron}
\end{figure}

L’algorithme QPS offre une bien meilleure performance pour les grandes valeurs de taux d'injection, en particulier à proximité de la limite de capacité du medium, par rapport à l'allocation série directe. En effet, allouer les RBs proportionnellement aux QSIs, élimine naturellement la probabilité que certains nœuds «épuisent» tous les RBs d’une trame et «affament» les autres nœuds. Même si l'allocation série avec DQSI fournit de meilleurs résultats (en particulier pour des trames de courte longueur), QPS apparaît comme une approche plus évolutive et équitable. 
 
\subsubsection*{5.2.2 Allocation QPS avec DQSI et EQSI}

Nous cherchons à accroître la performance de l'algorithme QPS en utilisant DQSI ou EQSI, en particulier pour les taux d'injection faibles. Comme pour les cas précédents, pour les approches décentralisées et centralisées, le calcul de DQSI et EQSI diffère.

Les Fig. 0.16 et Fig. 0.17 montrent la latence moyenne en fonction du taux d'injection dans le cas d’un trafic réaliste non-uniforme (DPBPP) pour l'allocation QPS (avec DQSI/EQSI), pour l'approche centralisée et décentralisée, et pour différentes longueurs de trame. 

 \begin{figure}[htbp]
  \centering
    \includegraphics[width=0.7\textwidth]{./Figures/QPS_decentral_DQSI_EQSI_DPBPP_copy.eps}
    \rule{35em}{0.5pt}
  \caption[Latence moyenne en fonction de l'augmentation du taux d'injection pour un trafic réaliste non-uniforme (DPBPP) pour l'allocation QPS (DQSI/EQSI) avec l'approche décentralisée pour différentes longueurs de trame.]{Latence moyenne en fonction de l'augmentation du taux d'injection pour un trafic réaliste non-uniforme (DPBPP) pour l'allocation QPS (DQSI/EQSI) avec l'approche décentralisée pour différentes longueurs de trame.}
  \label{fig:Electron}
\end{figure}

\begin{figure}[htbp]
  \centering
    \includegraphics[width=0.7\textwidth]{./Figures/QPS_central_DQSI_EQSI_DPBPP_copy.eps}
    \rule{35em}{0.5pt}
  \caption[Latence moyenne en fonction de l'augmentation du taux d'injection pour un trafic réaliste non-uniforme (DPBPP) pour l'allocation QPS (DQSI/EQSI) avec l'approche centralisée pour différentes longueurs de trame.]{Latence moyenne en fonction de l'augmentation du taux d'injection pour un trafic réaliste non-uniforme (DPBPP) pour l'allocation QPS (DQSI/EQSI) avec l'approche centralisée pour différentes longueurs de trame.}
  \label{fig:Electron}
\end{figure}

\newpage
\pagebreak

\subsubsection*{5.2.3 Classification arbresencte des algorithmes d'allocation proposés}

La Fig. 0.18 propose une classification des algorithmes introduits dans cette thèse sous forme d’arbre. A gauche sont représentés les approches d’allocation statiques (comme celui pouvant être utilisé par défaut avec une allocation équilibrée entre tous les tuilestes à 32 sous-porteuse chacun). A droite figurent les algorithmes d’allocation de bande passante dynamique proposés dans cette thèse. Ceux de ce chapitre 5 sont basées sur une file d’attente de transmission unique (``single queue") et se répartissent en deux grandes familles : série et QPS. Dans le chapitre 6, nous présentons un nouveau type d’algorithmes avec deux files d’attente de transmission, l'une pour les paquets courts de 1 flit (paquet de contrôle de cache et en-tête d'un paquet long) et l'autre pour les données des paquets longs ou ``payloads" (ligne de cache). Ces derniers algorithmes sont illustrés en grisé sur  l'extrême droit de la Fig. 0.18. 



\begin{figure}[htbp]
  \centering
    \includegraphics[height=0.75\textwidth, angle =90]{./Figures/radio_resource_alloc4.pdf}
    \rule{35em}{0.5pt}
  \caption[Arbre de classification des algorithmes d'allocation des ressources fréquentielles proposés dans cette thèse.]{Arbre de classification des algorithmes d'allocation des ressources fréquentielles proposés dans cette thèse.} 
  \label{fig:Electron}
\end{figure}


\newpage
\pagebreak

\section*{Chapitre 6 : Algorithme «Payload Channel»}

Le trafic de cohérence de cache sur une puce à grand nombre de coeurs a des caractéristiques très spécifiques par rapport aux systèmes classiques. Comme mentionné précédemment, une de ces caractéristiques est la longueur des paquets bimodaux. Ce mécanisme de cohérence de cache pour les architectures à plusieurs milliers de cœurs avec mémoire partagée impose un nombre élevé d’échange de messages de diffusion, et par conséquent une charge de trafic sur le la ligne de transmission RF filaire, ce qui est le prix à payer pour l'évolutivité. Il existe deux types de paquets de cohérence de cache circulant dans un réseau sur puce : 

\begin{itemize}
  \item Des paquets de contrôle courts (demandes pour lire une ligne d'adresse etc.)
  \item Des paquets longs qui portent les lignes de cache ou charge utile («payload» / demandes pour écrire à une ligne d'adresse, réponse pour la lecture d'une ligne d'adresse, etc.)
\end{itemize}

Dans le cadre de cette étude, la longueur d'un paquet court est choisie et fixée à 64 bits, ce qui peut changer selon l'architecture. Les paquets longs sont composés d'un en-tête de commande (header) de 64 bits, qui contient les informations nécessaires à la communication, comme les identificateurs (ID) de destination et de source, le type des paquets, etc., et les données en ligne de cache (charge utile ou «payload»). La taille de la ligne de cache est ici choisie et fixée à 64 octets (512 bits), soit des paquets longs de 576 bits. Compte tenu de la modulation QPSK utilisée par défaut, en cas d'attribution statique et uniforme de 32 sous-porteuses par tuileset, chaque tuileset reçoit ou émet 1 RB de 64 bits par symbole, un paquet long prend 9 symboles pour être transmis, même sans délai d'attente dans la file d'attente d’émission. Considérant qu’un symbole OFDM dure un peu plus de 50 ns, on peut comprendre le goulot d'étranglement que les paquets longs créent pour l'interconnexion sur puce. 

La taille de la ligne de cache a un impact significatif sur la performance du système de mémoire partagée. En cas de mémoires caches très grandes, utiliser de grandes lignes de cache est essentiel. Plus les lignes de cache sont grandes, plus cela diminue le taux de défaut de cache en général. Nous pouvons prédire que la meilleure performance sera acquise pour de plus grandes lignes de cache dans les architectures à milliers de coeurs avec mémoire partagée. En outre, une interconnexion reconfigurable et efficace, donc à faible latence, amortit la difficulté de transport de grandes lignes de cache, ce qui augmente les performances du système.

C’est en prenant tous ces aspects en considération que nous proposons un nouvel algorithme d'allocation de la bande passante pour l'interconnexion RF OFDMA de WiNoCoD. L’objectif est de diminuer considérablement le temps de latence des paquets longs, en transmettant les lignes de cache ou charges utiles (payload) en un seul symbole. Sont exploités ici la capacité de diffusion intrinsèque et de reconfigurabilité de l’OFDMA. Ici, nous choisissons de considérer une taille différente pour les paquets longs, afin de simplifier notre explication, mais aussi parce que les paquets longs de charge utile ont avantage à regrouper un grand nombre de flits. A la différence  des lignes de cache utilisés dans la première phase du projet (64 octets - 512 bits), cet algorithme est optimisé spécialement pour les lignes de cache 256 octets (2048 bits).

Dans ce cas, l'algorithme statique transmet les paquets longs dans une durée minimale égale à 33 symboles même sans délai d'attente en file d'attente (plus de 1650 ns), qui est très prohibitif.



\subsection*{6.1 : Algorithme «Payload Channel» avec Bande Passante de Base Statique}

Notre algorithme repose sur l'idée de transmettre des charges utiles de 2048 bits de paquets longs dans un seul symbole OFDM, en utilisant des 1024 sous-porteuses modulées en QPSK (toute labande passante). Les paquets de contrôle ont une taille de 64 bits (un seul flit), ce qui correspond à 70-80\% de tous les paquets et les paquets longs ont un flit d’en-tête qui précède la charge utile (ligne de cache). Notre algorithme original «payload channel» exploite ces bits indicateurs pour permettre la transmission de la charge utile des paquets longs dans un seul symbole OFDM, sans utiliser de surcharge de signalisation supplémentaire. 

Initialement, 32 sous-porteuses sont allouées à chaque tuileset, et nous les nommons canaux de base (\textit{home channel}). Comme la modulation QPSK est utilisée, ces canaux de base peuvent transporter 1 flit par symbole, soit un paquet court de contrôle ou un en-tête de paquet long. Tout d'abord, à la différence des architectures et solutions précédemment présentées, chaque tuileset a deux files d'attente de transmission différentes au niveau de leurs interfaces RF. Chaque fois qu'un nouveau paquet long arrive à l'interface RF pour être émis sur l’interconnexion RF, il est segmenté en deux sous-parties : 

\begin{itemize}
  \item Son en-tête, qui est mis en mémoire dans la file d'attente primaire de paquets courts
  \item Sa charge utile ou ``payload", qui est mise en mémoire la file d'attente secondaire de charge utiles à la manière d'une FIFO. 
\end{itemize}

\begin{figure}[htbp]
  \centering
    \includegraphics[width=0.8\textwidth]{./Figures/PayloadChannelAlgorithm01.pdf}
    \rule{35em}{0.5pt}
  \caption[Deux files d'attente de transmission séparées pour l'algorithme de canal de charge utile.]{Deux files d'attente de transmission séparées pour l'algorithme «payload channel».}
  \label{fig:Electron}
\end{figure}

Ceci est illustré sur la Fig. 0.19. La motivation de l’emploi de deux files d'attente séparées pour les en-têtes et paquets courts d’une part, et les charges utiles d’autre part, est d'éviter l'incohérence entre les en-têtes transmis et de leurs charges utiles, mais aussi de permettre la transmission d'un nouveau paquet avant de transmettre la charge utile d'un paquet précédent. 

Quand un tuileset transmet un en-tête de paquet long sur son canal de base (home channel), chaque tuileset peut le recevoir et décoder son contenu, grâce à la capacité de diffusion intrinsèque de l'interconnexion OFDMA. Chaque tuileset peut utiliser de simples unités de traitement pour vérifier les bits indicateurs des paquets et ainsi déterminer s’il s’agit d’un paquet long ou non. Quand les contrôleurs RF des tuilesets détectent un en-tête de paquet long, ils enregistrent le tuileset-ID correspondant (tuileset qui souhaite transmettre sa charge utile dans un seul symbole) en insérant l'ID dans le \textit{registre de la charge utile} (\textit{payload register}). Le Registre de la charge utile est une file d'attente simple de type FIFO au niveau de l'interface RF de chaque tuileset, qui met en mémoire les IDs des tuilesets qui veulent transmettre des charges utiles. Le contenu des registres de la charge utile est identique dans tous les tuilesets, afin d'éviter des incohérences.

Toutefois, l'acquisition du flit d’en-tête, le traitement et la reconfiguration de la bande passante prennent un certain  temps en raison des délais de propagation, de synchronisation et de calcul des retards. Par conséquent, nous avons tenu compte d’un temps d'attente de 1 symbole (50 ns) pour l’ensemble de ces retards et l'activation de l'algorithme. Notez également que, plusieurs en-têtes de paquets longs de différents tuilesets peuvent être détectés dans un symbole. Leurs identifiants sont enregistrés dans les registres de la charge utile via leur Tuileset-ID reçus dans le même symbole. Au début de chaque symbole, les tuilesets contrôlent leurs registres de charge utile. Si le registre de la charge utile est vide, cela signifie qu'il n'y a pas de tuileset qui veut actuellement transmettre une charge utile. La transmission reprend alors sa configuration par défaut d’un RB par tuileset.
Toutefois, si le registre de la charge utile n'est pas vide, le premier ID dans le registre transmet sa charge utile en prenant la place des canaux de base. Le système retourne à la configuration de canaux de base, que si il n'y a pas tuileset reste dans le registre de charge utile. Cette procédure est illustrée sur la Fig. 0.20 pour un scénario.

\begin{figure}[htbp]
  \centering
    \includegraphics[width=0.8\textwidth]{./Figures/PayloadChannelAlgorithm02.pdf}
    \rule{35em}{0.5pt}
  \caption[La procédure de transmission sur «payload channel» est illustrée pour un scénario.]{La procédure de transmission pour l'algorithme «payload channel» est illustrée pour un scénario.}
  \label{fig:Electron}
\end{figure}

Fig. 0.21 montre la latence moyenne de livraison des paquets en fonction de l'augmentation du taux d'injection pour notre algorithme «payload channel» et un cas statique (où chaque tuileset a un RB dans chaque symbole), sous trafic Poissonien uniforme. Nous avons également tiré une approximation analytique de la latence moyenne de cet algorithme, en utilisant les principes de la théorie des files d'attente de l'état de l'art. Notre algorithme innovant peut diminuer la latence moyenne jusqu'à 10 fois dans certains cas, grâce à son mécanisme simple, mais efficace.


\begin{figure}[htbp]
  \centering
    \includegraphics[width=0.8\textwidth]{./Figures/PayloadChannel_AvgLatency_Uniform.eps}
    \rule{35em}{0.5pt}
  \caption[Latence moyenne en fonction de l'augmentation du taux d'injection pour un trafic poisson non-uniforme pour l'algorithme «payload channel».]{Latence moyenne en fonction de l'augmentation du taux d'injection pour un trafic poisson non-uniforme pour l'algorithme «payload channel».}
  \label{fig:Electron}
\end{figure}

\subsection*{6.2 : Algorithme «Payload Channel» avec Bande Passante de Base Dynamique}

\begin{figure}[htbp]
  \centering
    \includegraphics[width=0.8\textwidth]{./Figures/PayloadChannelAlgorithm03.pdf}
    \rule{35em}{0.5pt}
  \caption[Arbitrage de RBs dans une trame pour l'algorithme «payload channel» dynamique.]{Arbitrage de RBs dans une trame pour l'algorithme «payload channel» dynamique.}
  \label{fig:Electron}
\end{figure}

Le déséquilibre spatial du trafic de cohérence de cache a été discuté précédemment. Notre algorithme «payload channel» a besoin d'une modification afin de faire face à cette situation. À cette fin, nous proposons l'algorithme « payload channel » avec une bande passante de base dynamique, en fusionnant l'algorithme « payload channel » avec l'algorithme QPS centralisé, qui a été expliqué dans le chapitre 5. L'idée est de changer le nombre de canaux de base de chaque tuileset, à l'aide d'une unité centrale intelligente (CIU), de la même manière que dans les mécanismes dynamiques d'algorithmes précédents. De la même manière qu’évoqué précédemment, sur le premier symbole de chaque trame, chaque tuileset diffuse son QSI. Puis le CIU calcule les QSIs prédit (EQSI) des tuilesets, et en déduit l’allocation des RBs (canaux de base dans ce cas) pour les tuilesets selon l'algorithme QPS. Cependant, dans le cas où le canal de charge utile n’est pas utilisé, selon les messages envoyés en réponse par le CIU sur certains symboles et sous-porteuses pré-déterminés, les tuilesets reconfigurent leur allocation des sous-porteuses pour les canaux de base à la trame suivante. Cette procédure est illustrée en détail sur la Fig. 0.22. 


\begin{figure}[htbp]
  \centering
    \includegraphics[width=0.8\textwidth]{./Figures/PayloadChannel_AvgLatency_NonUniformDPPBP_BandwidthAllocation.eps}
    \rule{35em}{0.5pt}
  \caption[Latence moyenne en fonction de l'augmentation du taux d'injection un trafic réaliste non-uniforme (DPBPP) pour l'algorithme «payload channel» dynamique.]{Latence moyenne en fonction de l'augmentation du taux d'injection un trafic réaliste non-uniforme (DPBPP) pour l'algorithme «payload channel» dynamique.}
  \label{fig:Electron}
\end{figure}

Fig. 0.23 montre l’évolution de la latence moyenne en fonction de l'augmentation du taux d'injection pour l’algorithme «payload channel» dynamique et l'algorithme QPS simple, dans le cas d’un trafic DPBPP non-uniforme, pour une longueur de trame de 16 symboles. Nous remarquons que nous pouvons diminuer la latence moyenne de paquets de manière drastique en exploitant les longueurs bimodale des paquets sur puce.

\section*{Chapitre 7 : Choix Dynamique de l'Ordre de Modulation}

En règle générale pour les communications numériques, on sait qu’il existe une relation exponentielle entre la puissance de transmission et le nombre de bits par symbole transmis, pour un taux d'erreur donné ou un rapport signal à bruit donné. Un autre avantage de l'utilisation de l'OFDMA dans WiNoCoD est la possibilité de modifier les ordres de modulation dynamiquement sur différents symboles et différentes sous-porteuses. Dans le cadre du projet WiNoCoD, quatre ordres de modulation ont été considérés: BPSK, QPSK, 16-QAM et 64-QAM, soit 1,2,4 et 6 bits par sous-porteuse respectivement. Dans notre étude, nous utilisons l'équation exponentielle, qui repose sur la relation issue de la théorie de l'information entre ordre de modulation et puissance. Cela permet de s’affranchir d'un taux d'erreur binaire spécifique, mais implique aussi l’utilisation de techniques de codage de canal qui ne sont pas considérées dans le cadre de cette étude. En outre, nous avons décidé d'employer les ordres de modulation jusqu'à 256-QAM, incluant également 8-PSK, 32-QAM et 128-QAM. 

Nous avons développé deux algorithmes inspirés de la littérature mais modifiés pour nos besoins. Le premier algorithme vise à sélectionner dynamiquement l'ordre de modulation le plus bas (par conséquent, la puissance d'émission minimale), tout en essayant de respecter une limite sur la latence maximale d'un paquet. En raison de la nature multi-canaux de WiNoCoD, nous avons redéfini cet algorithme, où il peut être également considéré pour des communications génériques. Par exemple, sur la Fig. 0.24, on voit qu’avec l'algorithme proposé, on peut diminuer la consommation d'énergie moyenne jusqu'à 5 fois, mais cela au détriment de la latence maximale qui connait alors une augmentation de quelques dizaines de symboles. Notre deuxième algorithme définit une limite maximale sur la latence moyenne. Par exemple, dans cet exemple spécifique, la Fig. 0.25 montre que nous pouvons diminuer la consommation moyenne d'énergie jusqu'à 4 fois, en augmentant la latence moyenne de quelques symboles. 

Une étude de capacité au sens de la théorie de l'information a aussi été menée.

\begin{figure}[htbp]
  \centering
    \includegraphics[width=0.8\textwidth]{./Figures/MaxDelayBound_InjRate8_NonUniPoiss_AvgPowers.eps}
    \rule{35em}{0.5pt}
  \caption[Le compromis entre latence maximale et puissance moyenne avec l'algorithme de choix dynamique de l'ordre de modulation pour un trafic Poisson non-uniforme.]{Le compromis entre latence maximale et puissance moyenne avec l'algorithme de choix dynamique de l'ordre de modulation pour un trafic Poisson non-uniforme.}
  \label{fig:Electron}
\end{figure}

\begin{figure}[htbp]
  \centering
    \includegraphics[width=0.8\textwidth]{./Figures/avgDelayBound_T16_Inj16_DPBPP.eps}
    \rule{35em}{0.5pt}
  \caption[Le compromis entre latence moyenne et puissance moyenne avec l'algorithme de choix dynamique de l'ordre de modulation pour un trafic DPBPP non-uniforme.]{Le compromis entre latence moyenne et puissance moyenne avec l'algorithme de choix dynamique de l'ordre de modulation pour un trafic DPBPP non-uniforme.}
  \label{fig:Electron}
\end{figure}

\section*{Chapitre 8 : Conclusion}

Dans ce travail de thèse qui a été effectué dans le cadre du projet WiNoCoD, nous avons démontré la faisabilité de l'utilisation OFDMA comme mécanisme de modulation sur une interconnexion RF filaire sur-puce pour une architecture massive manycore. Nous avons expliqué et exploité les avantages que peuvent offrir l’OFDM et l’OFDMA, notamment en termes de reconfiguration et de capacité de diffusion. Nous avons développé et analysé les performances de plusieurs mécanismes et algorithmes efficaces d'allocation de la bande passante, en tenant compte des contraintes et des exigences de l'environnement sur puce très spécifique. Nous avons également etudié des algorithmes de sélection de commande de modulation dynamiques qui offrent un compromis optimal entre la latence et la consommation d'énergie. Les contributions de cette thèse sont :

\begin{itemize}
  \item Une évaluation de la faisabilité d'une interconnexion RF OFDMA sur puce au niveau de la couche réseau. 
  \item Des algorithmes innovants d'allocation de bande pour cette interconnexion RF, adaptées aux exigences tres spécifiques des puces ayant des milliers de coeurs.
  \item Un nouvel algorithme d'allocation de bande optimisé pour des longueurs bimodales de paquets est proposé pour les réseaux sur puce.
  \item Deux algorithmes différents de sélection d'ordre de modulation sont proposés pour un compromis entre la latence et la puissance consommée.
  \item La puissance d'emission minimum sur l'interconnexion RF est evaluée par une approche basée sur la théorie de l'information (non présenté dans ce résumé en français).

\end{itemize}

